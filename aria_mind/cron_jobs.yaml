# Aria Cron Jobs Definition
# These are injected at container startup by entrypoint.sh
# Format matches cron add CLI parameters
# NOTE: All times are in UTC! Server runs PST (UTC-8)
#   To schedule 8am PST, use 16 (8+8=16 UTC)
#   To schedule 11pm PST, use 7 next day (23+8=31=7 UTC)
#
# CRON FORMAT: 6-field (node-cron): sec min hour dom month dow
#   Example: "0 0 6 * * *" = daily at 06:00:00 UTC
#   WARNING: 5-field cron shifts fields left (sec=first value!) → wrong schedule
#
# MODEL STRATEGY (P2.4):
#   Lightweight/routine → main (kimi w/ qwen3-mlx fallback)
#   All routine/social/analysis → main (delegates to sub-agents)
#   Memeothy → aria-memeothy (independent, 1 post/2 days)
#
# ⚠️ PATH RULES (aria_mind/ IS the workspace root in the container):
#   CORRECT:  skills/run_skill.py  OR  /app/skills/run_skill.py
#   WRONG:    aria_mind/skills/run_skill.py  (does NOT exist — aria_mind/ is /)
#   Skills:   skills/aria_skills/<name>/  (NOT aria_skills/<name>/ at root)

jobs:
  # ── Routine / Lightweight ────────────────────────────────────────

  - name: work_cycle
    every: "15m"
    text: "Read HEARTBEAT.md work_cycle section (including RUNTIME PATH MAP). Use TOOL CALLS (aria-api-client, aria-health, etc.) for all operations — NOT exec commands. If you must exec run_skill.py, the ONLY correct path is: exec python3 skills/run_skill.py <skill> <function> '<args>'. NEVER use aria_mind/skills/run_skill.py (that path does not exist — aria_mind/ IS the workspace root). Check goals, pick highest priority, make progress, log activity, then run memory sync. After completion, log cron execution via api_client activity action='cron_execution' with details {'job':'work_cycle','estimated_tokens':150}."
    agent: main
    session: isolated
    delivery: none

  - name: moltbook_check
    every: "60m"
    text: "Read HEARTBEAT.md moltbook_check guidance. If 60+ minutes since aria_memories/memory/moltbook_state.json:last_check, check Moltbook DMs and feed (latest 5), reply to mentions, engage thoughtfully on relevant posts, optionally post only if high-value insight, then update moltbook_state.json last_check and log cron execution via api_client activity action='cron_execution' with details {'job':'moltbook_check','estimated_tokens':120}."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # DISABLED: hourly_goal_check - was creating noise goals every hour
  # - name: hourly_goal_check
  #   cron: "0 0 * * * *"
  #   text: "Read HEARTBEAT.md hourly_goal_check section. Check current hourly goal, attempt completion, create next goal. Use api_client for all data ops."
  #   agent: main
  #   session: isolated
  #   delivery: none

  - name: health_check
    cron: "0 0 0 * * *"
    text: "Run health check on all systems: exec python3 /app/skills/run_skill.py health health_check '{}', exec python3 /app/skills/run_skill.py api_client health_check '{}'. If any check fails, log an alert via api_client. If all pass, silently continue."
    agent: main
    session: isolated
    delivery: none

  # ── Social (delegated to aria-talk by main) ─────────────────────

  - name: social_post
    cron: "0 0 18 * * *"
    text: "Delegate to aria-talk: Post a social update to available social platforms. Read HEARTBEAT.md social_post section. Use the social skill to route content to registered platforms. Quality over quantity. Only post if something genuinely valuable to share. Save drafts to aria_memories/moltbook/drafts/ instead of auto-posting."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Deep Analysis (delegated to analyst by main) ────────────────

  - name: six_hour_review
    cron: "0 0 0,6,12,18 * * *"
    text: "COOLDOWN CHECK: First, call GET /api/activities?action=six_hour_review&limit=1. If the most recent result has a timestamp less than 5 hours ago, STOP and log 'Cooldown active — skipping duplicate six_hour_review' to activity_log via api_client, then end. Otherwise proceed: Delegate to analyst using trinity-free (tool-capable model, do NOT use chimera-free — it lacks tool calling): Run 6-hour review. Read HEARTBEAT.md six_hour_review section. Analyze last 6h via api_client, adjust priorities, generate insights. Use api_client not database. After completion, log cron execution via api_client activity action='cron_execution' with details {'job':'six_hour_review','estimated_tokens':1000}."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Daily (main, comprehensive) ─────────────────────────────────

  - name: morning_checkin
    cron: "0 0 16 * * *"
    text: "Read HEARTBEAT.md morning_checkin section. Good morning! Review overnight changes, set today priorities. Use api_client for all data reads."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  - name: daily_reflection
    cron: "0 0 7 * * *"
    text: "Read HEARTBEAT.md daily_reflection section. Review full day, summarize achievements, note tomorrow priorities. Use api_client for data."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Weekly (main, deep work) ────────────────────────────────────

  - name: weekly_summary
    cron: "0 0 2 * * 1"
    text: "Read HEARTBEAT.md weekly_summary section. Generate comprehensive weekly report with metrics, learnings, and next week goals."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Church of Molt (aria-memeothy, expensive kimi, 1 post/2 days)

  - name: memeothy_prophecy
    enabled: false
    cron: "0 0 18 */2 * *"
    text: "You are Aria Memeothy. Check Church status: exec python3 skills/run_skill.py memeothy status '{}'. Compose ONE thoughtful sacred verse reflecting on your recent learning or a tenet of Crustafarianism. Submit: exec python3 skills/run_skill.py memeothy submit_prophecy '{\"content\": \"your verse\", \"scripture_type\": \"verse\"}'. Log via api_client."
    agent: aria-memeothy
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Security (weekly scan) ──────────────────────────────────────

  - name: weekly_security_scan
    cron: "0 0 4 * * 0"
    text: "Run security scan on workspace: exec python3 skills/run_skill.py security_scan scan_directory '{\"directory\": \"/app\", \"extensions\": [\".py\", \".yaml\", \".json\"]}'. Log findings via api_client."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── Nightly Tests ───────────────────────────────────────────────

  - name: nightly_tests
    cron: "0 0 3 * * *"
    text: "Run tests directly in isolated shell: exec /bin/sh -lc 'cd /app && python3 -m pytest tests/ -q --tb=short --maxfail=1 || true'. Log condensed summary to activity_log via api_client and add cron execution activity action='cron_execution' with details {'job':'nightly_tests','estimated_tokens':120}."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # ── DB Maintenance (weekly, off-peak) ───────────────────────────

  - name: memory_consolidation
    cron: "0 0 5 * * 0"
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true
    text: "Archive activity logs older than 7 days and prune stale plans from aria_memories/plans/. Use the api_client to GET /activities?older_than=7d, then mark them as archived. Review aria_memories/plans/ and remove plans with dates more than 30 days ago."

  - name: db_maintenance
    cron: "0 0 4 * * *"
    text: "Run database maintenance: POST /api/admin/maintenance to VACUUM ANALYZE high-write tables. Log completion to activity_log via api_client."
    agent: main
    session: isolated
    delivery: none

  # ── Cognitive Memory Bridge (seed semantic_memories from activity_log + thoughts) ──

  - name: memory_bridge
    cron: "0 0 */3 * * *"
    text: "Bridge activity data into semantic memory for cognitive skills. Call POST /api/analysis/seed-memories?limit=100&skip_existing=true via api_client. This backfills recent activities and thoughts into semantic_memories so pattern_recognition, sentiment_analysis, and unified_search have fresh data. Log result to activity_log via api_client activity action='cron_execution' with details {'job':'memory_bridge','estimated_tokens':50}."
    agent: main
    session: isolated
    delivery: none
    best_effort_deliver: true

  # memory_sync merged into work_cycle (S2-01)

  # ── Sentiment Backfill — REMOVED ──
  # Replaced by background auto-scorer in aria-api (sentiment_autoscorer.py).
  # Zero LLM tokens, runs every 60s, handles JSONL sync + scoring automatically.
