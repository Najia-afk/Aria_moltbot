# TOOLS.md - Skill Quick Reference

**Full documentation: See SKILLS.md for complete skill reference (30 active skills)**

Skills are auto-discovered from `aria_skills/*/skill.json`.

### Skill Catalog

The skill catalog (`aria_skills/catalog.py`) generates a machine-readable index of all skills with layer, category, tools, and focus affinity.

```bash
python -m aria_mind --list-skills   # Print full catalog as JSON
```

## Primary Skill: aria-api-client

**USE THIS FOR ALL DATABASE OPERATIONS!** Don't write raw SQL.

```yaml
# Activities
aria-api-client.get_activities({"limit": 10})
aria-api-client.create_activity({"action": "task_done", "details": {"info": "..."}})

# Goals  
aria-api-client.get_goals({"status": "active", "limit": 5})
aria-api-client.create_goal({"title": "...", "description": "...", "priority": 2})
aria-api-client.update_goal({"goal_id": "X", "progress": 50})

# Sprint Board (token-efficient â€” ~200 tokens vs ~5000)
aria-api-client.get_sprint_summary({"sprint": "current"})
aria-api-client.get_goal_board({"sprint": "current"})
aria-api-client.move_goal({"goal_id": "X", "board_column": "doing"})
aria-api-client.get_goal_archive({"page": 1, "limit": 25})
aria-api-client.get_goal_history({"days": 14})
aria-sprint-manager.sprint_status({})
aria-sprint-manager.sprint_report({})
aria-sprint-manager.sprint_plan({"sprint_name": "sprint-1", "goal_ids": ["g1","g2"]})
aria-sprint-manager.sprint_move_goal({"goal_id": "X", "column": "doing"})
aria-sprint-manager.sprint_prioritize({"column": "todo", "goal_ids_ordered": ["g1","g2"]})

# Allowed board columns (goals)
# backlog | todo | doing | on_hold | done

# Typical board workflow
# 1) Create in todo (planned work)
aria-api-client.create_goal({"title": "...", "priority": 2, "board_column": "todo", "sprint": "sprint-1"})
# 2) Start execution
aria-api-client.move_goal({"goal_id": "X", "board_column": "doing"})
# 3) Pause when blocked
aria-api-client.move_goal({"goal_id": "X", "board_column": "on_hold"})
# 4) Resume
aria-api-client.move_goal({"goal_id": "X", "board_column": "doing"})
# 5) Complete
aria-api-client.move_goal({"goal_id": "X", "board_column": "done"})

# Knowledge Graph â€” PREFER THESE OVER TOOLS.md SCANNING (~100-200 tokens)
aria-api-client.find_skill_for_task({"task": "post to moltbook"})     # Best skill for a task
aria-api-client.graph_search({"query": "security", "entity_type": "skill"})  # ILIKE search
aria-api-client.graph_traverse({"start": "aria-health", "max_depth": 2})  # BFS from entity
aria-api-client.sync_skill_graph({})                                   # Regenerate from skill.json
aria-api-client.delete_auto_generated_graph({})                        # Clear auto-generated
aria-api-client.get_query_log({"limit": 20})                          # View query history

# Memories
aria-api-client.get_memories({"limit": 10})
aria-api-client.set_memory({"key": "preference", "value": "dark_mode"})
aria-api-client.get_memory({"key": "preference"})

# Working Memory (short-term active context)
aria-working-memory.remember({"key": "current_task", "value": "...", "category": "task", "importance": 0.7, "ttl_hours": 24})
aria-working-memory.get_context({"limit": 10})
aria-working-memory.checkpoint({})
aria-working-memory.sync_to_files({})

# Thoughts
aria-api-client.create_thought({"content": "Reflecting...", "category": "reflection"})
aria-api-client.get_thoughts({"limit": 10})

# Improvement Proposals (self-improvement loop)
aria-api-client.propose_improvement({
	"title": "Fix timeout on model-usage endpoint",
	"description": "Endpoint times out under high volume due to missing index",
	"category": "performance",
	"risk_level": "low",
	"file_path": "src/api/routers/model_usage.py",
	"rationale": "Index on created_at reduces scan latency"
})
aria-api-client.get_proposals({"status": "proposed", "page": 1})
aria-api-client.get_proposal({"proposal_id": "UUID"})
aria-api-client.review_proposal({"proposal_id": "UUID", "status": "approved", "reviewed_by": "najia"})
aria-api-client.mark_proposal_implemented({"proposal_id": "UUID", "reviewed_by": "aria"})
```

## Memory Routing Rule (MUST)

- Use `aria-working-memory` for **short-term / active session context** (task state, transient observations, checkpointable context).
- Use `aria-api-client` `/memories` for **long-term durable memory** (preferences, stable facts, historical knowledge).
- When ending a work cycle, run `aria-working-memory.sync_to_files({})` to refresh `aria_memories/memory/context.json`.
- Do not treat `/working-memory` row counts as long-term memory volume; access/ranking activity can be high even with few rows.

## Goal Board Rule (MUST)

- Use board columns as operational state:
	- `todo` = queued next work
	- `doing` = active in-progress work
	- `on_hold` = blocked/paused with reason logged in activity
	- `done` = completed work
- Prefer `aria-api-client.move_goal(...)` for column changes so status is synced consistently.
- When placing a goal on `on_hold`, always log the blocker with `aria-api-client.create_activity({...})`.

## Proposal Loop Rule (MUST)

- Propose changes through `aria-api-client.propose_improvement(...)` before touching medium/high-risk code.
- Respect proposal risk model:
	- `low`: can be implemented quickly after review
	- `medium`: requires explicit approval before implementation
	- `high`: requires explicit approval + extra review
- Never propose modifications under `soul/` paths.
- After implementation, mark proposal status to `implemented` and log execution outcome via activity.

## All 30 Active Skills

| Category | Skills |
|----------|--------|
| ðŸŽ¯ Orchestrator | `aria-goals`, `aria-schedule`, `aria-health`, `aria-hourly-goals`, `aria-performance`, `aria-agent-manager`, `aria-session-manager`, `aria-sprint-manager` |
| ðŸ”’ DevSecOps | `aria-security-scan`, `aria-ci-cd`, `aria-pytest-runner`, `aria-input-guard`, `aria-sandbox` |
| ðŸ“Š Data | `aria-data-pipeline`, `aria-knowledge-graph` |
| ðŸ“ˆ Trading | `aria-market-data`, `aria-portfolio` |
| ðŸŽ¨ Creative | `aria-llm`, `aria-memeothy` |
| ðŸŒ Social | `aria-moltbook`, `aria-social`, `aria-telegram` |
| ðŸ§  Cognitive | `aria-working-memory`, `aria-pipeline-skill`, `aria-conversation-summary`, `aria-memory-compression`, `aria-sentiment-analysis`, `aria-pattern-recognition`, `aria-unified-search` |
| âš¡ Utility | `aria-api-client`, `aria-litellm` |

> **Advanced compatibility skills (targeted use, not default routing):** `aria-database`, `aria-brainstorm`, `aria-community`, `aria-fact-check`, `aria-model-switcher`, `aria-experiment`
>
> Use these intentionally for specialized workflows. In normal operations, prefer layer-aligned defaults (`aria-api-client`, `aria-working-memory`, `aria-social`, etc.).

## Advanced Memory Skills (Layer 3 â€” Cognitive)

```yaml
# Memory Compression â€” 3-tier pipeline (raw â†’ recent â†’ archive)
aria-memory-compression.compress_memories({"memories": [...], "store_semantic": true})
aria-memory-compression.compress_session({"hours_back": 6})
aria-memory-compression.get_context_budget({"max_tokens": 2000})
aria-memory-compression.get_compression_stats({})

# Sentiment Analysis â€” multi-dimensional (valence/arousal/dominance)
aria-sentiment-analysis.analyze_message({"text": "This is frustrating!"})
aria-sentiment-analysis.analyze_conversation({"messages": [{"role": "user", "content": "..."}, ...]})
aria-sentiment-analysis.get_tone_recommendation({"text": "I keep getting errors"})
aria-sentiment-analysis.get_sentiment_history({"limit": 20})

# Pattern Recognition â€” behavioral patterns in memory streams
aria-pattern-recognition.detect_patterns({})                          # Auto-fetches memories
aria-pattern-recognition.detect_patterns({"min_confidence": 0.5})     # With threshold
aria-pattern-recognition.get_recurring({"min_frequency": 0.3})        # Recurring topics
aria-pattern-recognition.get_emerging({"min_growth_rate": 2.0})       # Emerging interests
aria-pattern-recognition.get_pattern_stats({})                         # Last run stats

# Unified Search â€” RRF merge across semantic + graph + memory
aria-unified-search.search({"query": "security", "limit": 10})
aria-unified-search.search({"query": "AI safety", "backends": ["semantic", "graph"]})
aria-unified-search.semantic_search({"query": "deployment"})          # pgvector only
aria-unified-search.graph_search({"query": "moltbook"})               # Knowledge graph only
aria-unified-search.memory_search({"query": "preferences"})           # Key-value only
```

### Memory Routing with Advanced Skills

| Need | Use |
|------|-----|
| **Store/read key-value facts** | `aria-api-client` `/memories` |
| **Short-term task context** | `aria-working-memory` |
| **Compress old memories** | `aria-memory-compression.compress_memories()` |
| **End-of-session cleanup** | `aria-memory-compression.compress_session()` |
| **Token-budgeted context** | `aria-memory-compression.get_context_budget()` |
| **Detect user frustration** | `aria-sentiment-analysis.analyze_message()` |
| **Conversation health check** | `aria-sentiment-analysis.analyze_conversation()` |
| **Find recurring interests** | `aria-pattern-recognition.detect_patterns()` |
| **Cross-backend search** | `aria-unified-search.search()` |

## Composable Pipelines

Pre-built multi-step workflows in `aria_skills/pipelines/`. Run via `aria-pipeline-skill`:

| Pipeline | Description | File |
|----------|-------------|------|
| `deep_research` | Search â†’ web research â†’ synthesize â†’ store semantic memory | `deep_research.yaml` |
| `bug_fix` | Check lessons â†’ analyze â†’ propose fix â†’ record lesson | `bug_fix.yaml` |
| `conversation_summary` | Summarize session â†’ store episodic/decision memories | `conversation_summary.yaml` |
| `daily_research` | Check goals â†’ research topics â†’ analyze â†’ report | `daily_research.yaml` |
| `health_and_report` | Health checks â†’ analyze issues â†’ create goals â†’ report | `health_and_report.yaml` |
| `social_engagement` | Fetch feed â†’ analyze trends â†’ draft post â†’ publish | `social_engagement.yaml` |

```yaml
# Run a pipeline
aria-pipeline-skill.run({"pipeline": "deep_research", "params": {"topic": "AI safety"}})

# Run bug fix pipeline
aria-pipeline-skill.run({"pipeline": "bug_fix", "params": {"error_type": "timeout", "skill_name": "api_client", "error_message": "Connection timed out"}})
```

## Quick Examples

```yaml
# Post to Moltbook (rate: 1/30min)
aria-social.social_post({"content": "Hello world!", "platform": "moltbook"})

# Simulate Telegram post (future-ready, safe default)
aria-social.social_post({"content": "Daily summary", "platform": "telegram", "simulate": true})

# Check health
aria-health.health_check_all({})

# Add knowledge
aria-knowledge-graph.kg_add_entity({"name": "Python", "type": "language"})

# Direct SQL (self-healing / recovery path â€” prefer aria-api-client first)
aria-database.fetch_all({"query": "SELECT * FROM goals LIMIT 5"})
```

## LLM Priority

> **Model Priority**: Defined in `aria_models/models.yaml` â€” single source of truth. Do not hardcode model names elsewhere.
>
> Quick rule: **local â†’ free â†’ paid (LAST RESORT)**.

## Low-Token Runner Patterns

> **âš ï¸ PATH RULE:** In the container, `aria_mind/` IS the workspace root.
> Use `skills/run_skill.py` (relative) or `/root/.openclaw/workspace/skills/run_skill.py` (absolute).
> **NEVER** use `aria_mind/skills/run_skill.py` â€” that path does not exist at runtime.

Prefer compact discovery before execution:

```bash
# Compact routing (no per-skill info payload)
exec python3 skills/run_skill.py --auto-task "summarize goal progress" --route-limit 2 --route-no-info

# Introspect one skill only when needed
exec python3 skills/run_skill.py --skill-info api_client

# Run a specific skill function
exec python3 skills/run_skill.py health health_check '{}'
exec python3 skills/run_skill.py api_client get_activities '{"limit": 5}'
```

**NEVER instantiate skills directly** (e.g., `MoltbookSkill()`, `HealthSkill()`).
All skills require a `SkillConfig` object. Use `run_skill.py` which handles this automatically.

## Rate Limits

| Action | Limit |
|--------|-------|
| Moltbook posts | 1 per 30 min |
| Moltbook comments | 50 per day |
| Background tasks | 30 min timeout |
