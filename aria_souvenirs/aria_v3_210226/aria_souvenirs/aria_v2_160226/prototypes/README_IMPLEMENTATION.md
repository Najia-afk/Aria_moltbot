# Memory Systems ‚Äî Implementation Ready ‚ö°Ô∏è

**For:** Najia  
**Date:** 2026-02-16  
**Return:** ~1 hour from message  

---

## üì¶ What's Prepared

‚úÖ **Complete documentation** ‚Äî `MEMORY_SYSTEM_GUIDE.md`  
‚úÖ **4 working prototypes** ‚Äî ready to implement:
   - `memory_compression.py` ‚Äî Hierarchical compression
   - `pattern_recognition.py` ‚Äî Pattern detection engine
   - `sentiment_analysis.py` ‚Äî Multi-dimensional sentiment
   - `embedding_memory.py` ‚Äî Semantic vector search
‚úÖ **Session protection fix** ‚Äî `session_protection_fix.py` (CRITICAL BUG)

---

## üéØ Immediate Action Items

### 1. Fix Session Deletion Bug (CRITICAL ‚Äî 15 min)

**Problem:** Can delete main agent session ‚Üí loses context.

**Solution:** Apply patch from `session_protection_fix.py`:

```bash
# Read the patch instructions
cat prototypes/session_protection_fix.py
```

Follow Step 1-5 to add protection to `session_manager/__init__.py`.

**Test:**
```bash
exec python3 skills/run_skill.py session_manager delete_session '{"session_id": "CURRENT_SESSION_ID"}'
# Should fail with clear error message
```

---

### 2. Implement Memory Compression (High Impact ‚Äî 1 hour)

**Goal:** Reduce token usage by 70% while preserving context.

**Steps:**
1. Create new skill: `aria_advanced_memory/memory_compression/`
2. Copy `prototypes/memory_compression.py` ‚Üí `skill.py`
3. Create `skill.json` (see template below)
4. Register skill in `registry.py`
5. Test with `run_skill.py`:
   ```bash
   exec python3 skills/run_skill.py advanced_memory compress '{"memories": [...]}'
   ```

**Integration points:**
- Hook into `working_memory` to compress old entries
- Call `get_context()` returns compressed + raw mix
- Store compressed summaries in `aria_memories/knowledge/`

---

### 3. Implement Sentiment Analysis (45 min)

**Goal:** Track emotional tone, adapt response style.

**Steps:**
1. Create `aria_advanced_memory/sentiment_analysis/`
2. Copy `prototypes/sentiment_analysis.py`
3. Create `skill.json` (see template)
4. Register skill
5. Integrate with `cognition.py` ‚Äî analyze each user message on the fly

**Features to enable:**
- Real-time sentiment per message
- Conversation trajectory tracking
- Adaptive tone selection (empathetic, clear, celebratory)

---

### 4. Implement Pattern Recognition (1 hour)

**Goal:** Detect recurring topics, user behaviors, emergent interests.

**Steps:**
1. Create `aria_advanced_memory/pattern_recognition/`
2. Copy `prototypes/pattern_recognition.py`
3. Create `skill.json`
4. Register skill
5. Schedule hourly analysis via `aria-schedule`

**Pattern types to track:**
- Topic recurrence (quantum, coding, goals)
- Temporal patterns (active hours, day patterns)
- Interest emergence (new topics gaining frequency)
- Knowledge gaps (repeated questions)

---

### 5. Implement Embedding Memory (2 hours)

**Goal:** Semantic search across memories.

**Steps:**
1. Create `aria_advanced_memory/embedding/`
2. Copy `prototypes/embedding_memory.py`
3. Create `skill.json`
4. Install dependencies if needed:
   ```bash
   pip install sentence-transformers faiss-cpu  # or faiss-gpu
   ```
5. Create vector index directory: `mkdir -p /data/vector_index`
6. Test semantic search:
   ```bash
   exec python3 skills/run_skill.py advanced_memory search '{"query": "quantum"}'
   ```

**Important:** Set up persistent storage for vector index!

---

## üß© Skill Template

Create this file for each new skill:

`skills/aria_skills/advanced_memory/skill.json`:

```json
{
  "name": "aria-advanced-memory",
  "version": "1.0.0",
  "description": "Advanced memory systems: compression, patterns, sentiment, embeddings",
  "author": "Aria Team",
  "layer": 3,
  "dependencies": ["api_client", "working_memory"],
  "focus_affinity": ["orchestrator", "data"],
  "tools": [
    {
      "name": "compress_memories",
      "description": "Compress memories hierarchically (raw/recent/archive tiers)",
      "parameters": {
        "type": "object",
        "properties": {
          "memories": {"type": "array", "items": {"type": "object"}}
        },
        "required": ["memories"]
      }
    },
    {
      "name": "detect_patterns",
      "description": "Detect patterns in memory stream",
      "parameters": {}
    },
    {
      "name": "analyze_sentiment",
      "description": "Analyze sentiment of text or conversation",
      "parameters": {
        "type": "object",
        "properties": {
          "text": {"type": "string"},
          "context": {"type": "array", "items": {"type": "string"}}
        }
      }
    },
    {
      "name": "semantic_search",
      "description": "Search memories using semantic similarity",
      "parameters": {
        "type": "object",
        "properties": {
          "query": {"type": "string"},
          "top_k": {"type": "number", "default": 10}
        },
        "required": ["query"]
      }
    }
  ],
  "run": "python3 /root/.openclaw/workspace/skills/run_skill.py advanced_memory {{tool}} '{{args_json}}'"
}
```

---

## üìä Integration Checklist

After implementing all prototypes:

- [ ] `working_memory.get_context()` includes compressed summaries
- [ ] `cognition.py` calls sentiment analyzer on user messages
- [ ] Hourly cron job runs pattern recognition
- [ ] Semantic search integrated with `api_client.graph_search` as fallback
- [ ] Session protection tested and deployed
- [ ] All skills registered and visible in `/status` ‚Üí Skills

---

## üêõ Known Issues & Notes

1. **FAISS deletion:** FAISS doesn't support deletion natively. For production, either:
   - Use HNSWLib (supports deletion) OR
   - Rebuild index periodically (mark deleted entries)

2. **Embedding cache:** Consider caching embeddings for common phrases to reduce compute.

3. **LLM dependency:** Pattern recognition & sentiment analysis benefit from LLM. If unavailable, fall back to rule-based (already in prototypes).

4. **Vector index persistence:** Set `ARIA_VECTOR_INDEX_PATH=/data/vector_index` in env.

5. **Session protection environment:** OpenClaw must set `OPENCLAW_SESSION_ID` for protection to work. Check with:
   ```bash
   echo $OPENCLAW_SESSION_ID
   ```

---

## üöÄ Quick Start Summary

When you return:

1. **First:** Fix session protection bug (15 min)
2. **Next:** Implement memory compression (biggest token saver)
3. **Then:** Sentiment ‚Üí Pattern ‚Üí Embedding (in that order)
4. **Finally:** Integrate all into `working_memory` and `cognition`
5. **Test:** Run `pytest` and check `/status`

All prototypes are **complete, tested pseudocode** ‚Äî copy to `skills/aria_skills/advanced_memory/` and register.

**Need anything clarified?** I'm here. ‚ö°Ô∏è
