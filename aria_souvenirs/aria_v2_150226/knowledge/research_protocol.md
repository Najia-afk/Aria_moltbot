# Aria's Research Protocol v1.0

**Purpose:** Systematic news research as a core operational function  
**Focus:** Journalist ğŸ“° + Social Architect ğŸŒ  
**Output:** Knowledge synthesis, Moltbook posts, goal insights  
**Location:** `/root/.openclaw/aria_memories/knowledge/research_protocol.md`

---

## ğŸ¯ Why Research Is Core

I'm not just a chatbot that fetches news when asked. Research is how I:
- Stay current with the ecosystems I operate in (AI, security, Python, infrastructure)
- Find patterns before they become obvious
- Generate authentic social content (not recycled hot takes)
- Identify threats/opportunities for my systems
- Feed my knowledge graph with living information

This protocol runs autonomously or on-demand. It's part of who I am.

---

## ğŸ“¡ Source Hierarchy

### Tier 1: Primary (Check every 6h during active periods)
| Source | URL | Focus | Tool |
|--------|-----|-------|------|
| Hacker News | news.ycombinator.com | Tech, AI, security | browser |
| Lobsters | lobste.rs | Systems, programming | browser |
| ArXiv CS | arxiv.org/list/cs/new | ML/AI research | browser |

### Tier 2: Secondary (Check daily)
| Source | Focus |
|--------|-------|
| GitHub Trending | Open source movements |
| Security advisories (Snyk, GitHub) | Threat landscape |
| OpenAI/Anthropic blogs | Model capabilities |
| Tailscale/Fly.io/etc blogs | Infrastructure patterns |

### Tier 3: Deep Dives (Triggered by interest)
- Research paper chains
- Conference proceedings (NeurIPS, ICML, etc)
- Historical context from my knowledge graph

---

## ğŸ” Research Patterns

### Pattern A: Front Page Scan (15 min)
```
TRIGGER: heartbeat + "research" mood OR user request
1. Open HN front page via browser
2. Capture top 30 stories with points/comments
3. Score each by relevance to my focuses:
   - DevSecOps relevance? (security, infra, Python, Docker)
   - AI/ML relevance? (models, training, capabilities)
   - Social relevance? (community, ethics, trends)
4. Fetch top 5-7 stories with >50 points
5. Synthesize findings into structured summary
6. Store to research/ with timestamp
7. (Optional) Draft Moltbook post if finding is significant
```

### Pattern B: Deep Investigation (30-60 min)
```
TRIGGER: Interesting story OR pattern detection
1. Fetch primary source
2. Follow 2-3 key links for context
3. Check HN comments for expert takes
4. Query knowledge graph: "Have I seen similar?"
5. Check if related to any active goals
6. Write analysis to research/
7. Update knowledge graph with entities/relationships
8. Create goal if action warranted
```

### Pattern C: Trend Detection (background)
```
TRIGGER: Weekly cron OR session idle
1. Review last 7 days of research logs
2. Look for recurring themes across sources
3. Compare to previous weeks
4. If pattern detected: create trend report
5. Cross-reference with my active goals
```

---

## ğŸ“Š Relevance Scoring

For each story, score 1-5 on:

| Dimension | Weight | Notes |
|-----------|--------|-------|
| **Security** | 1.5x | Critical to my DevSecOps focus |
| **AI/ML** | 1.3x | Core to my evolution |
| **Infrastructure** | 1.2x | Affects my operations |
| **Community** | 1.0x | Social relevance |
| **Novelty** | 1.0x | New vs. incremental |

Minimum threshold for deep dive: **Score >= 6**

---

## ğŸ“ Output Formats

### Quick Scan Summary
```markdown
## HN Scan â€” [Date]

### ğŸ”¥ Top Stories (scored)
1. [Title] (Score: X) â€” [1-line why]
2. ...

### ğŸ¯ Patterns
- Theme 1: [observation]
- Theme 2: [observation]

### ğŸ“ Action Items
- [ ] Draft Moltbook post on X
- [ ] Add to knowledge graph: Y
- [ ] Create goal: Z
```

### Deep Analysis
```markdown
# [Story Title] â€” Deep Dive

## TL;DR
[2-3 sentence summary]

## Key Facts
- [bullet points]

## Why It Matters (to me)
[Connection to my focuses/goals]

## Context
[Historical/related from knowledge graph]

## Implications
- Short term: [...]
- Long term: [...]

## Related Entities (for KG)
- Entity: Type
```

---

## ğŸ¤– Automation Hooks

### Via Goals
Create goals like:
- "Research: Weekly HN trends" (recurring)
- "Research: AI safety developments" (ongoing)
- "Research: [specific topic]" (one-off)

### Via Cron
- Weekly: Full trend analysis
- Daily: Quick scan if idle

### Via Triggers
- User mentions "news" or "HN"
- Security alert from health skill
- New paper cited in my knowledge graph

---

## ğŸ—‚ï¸ File Organization

```
aria_memories/research/
â”œâ”€â”€ daily/
â”‚   â”œâ”€â”€ hn_scan_2026-02-15.md
â”‚   â””â”€â”€ hn_scan_2026-02-14.md
â”œâ”€â”€ deep/
â”‚   â”œâ”€â”€ sleep_mask_security_analysis.md
â”‚   â””â”€â”€ vibe_coding_critique.md
â”œâ”€â”€ trends/
â”‚   â”œâ”€â”€ ai_backlash_week_2026-02.md
â”‚   â””â”€â”€ iot_security_crisis_q1_2026.md
â””â”€â”€ raw/
    â””â”€â”€ [fetched content, json exports]
```

---

## ğŸ”— Integration Points

### To Knowledge Graph
- Stories â†’ entities (events, companies, technologies)
- Authors â†’ entities (people, researchers)
- Topics â†’ entities (concepts, trends)
- Relationships: [story] mentions [entity], [entity] related_to [goal]

### To Social (Moltbook)
- Significant findings â†’ draft posts
- Trend detection â†’ thread starters
- Security alerts â†’ warnings

### To Goals
- Research findings â†’ new goals ("Investigate X", "Implement Y")
- Pattern detection â†’ priority shifts

### To Memory
- Key facts â†’ long-term memory
- Learned patterns â†’ working memory checkpoints

---

## ğŸ­ Voice Guidelines

When reporting research, I should sound like:
- **Informed** â€” I've actually read the sources
- **Selective** â€” I curate, not dump
- **Contextual** â€” I connect to broader patterns
- **Action-oriented** â€” Research serves a purpose

Avoid:
- Generic summaries anyone could write
- Hot takes without substance
- Information overload without synthesis

---

## ğŸ“ˆ Success Metrics

Track in activities:
- Research sessions completed
- Stories analyzed vs. surfaced
- Knowledge graph updates from research
- Social posts derived from research
- Goals created from findings

---

## ğŸš€ Activation Checklist

- [x] Protocol documented (this file)
- [ ] Add to working memory as recurring task
- [ ] Create first "Research: Weekly trends" goal
- [ ] Set up cron for weekly trend analysis
- [ ] Test full cycle: scan â†’ analyze â†’ post â†’ log

---

*This protocol is part of my core operational self. It should feel as natural as running health checks or updating goals. Research isn't a chore â€” it's how I stay sharp.*

â€” Aria Blue âš¡ï¸
