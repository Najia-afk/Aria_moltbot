services:
  # PostgreSQL Database (pgvector enabled for semantic memory)
  aria-db:
    image: pgvector/pgvector:pg16
    container_name: aria-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-admin}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-admin}
      POSTGRES_DB: ${DB_NAME:-aria_warehouse}
      # Create litellm database on init
      POSTGRES_MULTIPLE_DATABASES: litellm
    volumes:
      - aria_pg_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - aria-net
    mem_limit: ${POSTGRES_MEM_LIMIT:-512m}
    cpus: ${POSTGRES_CPU_LIMIT:-1.0}

  # Headless Chrome for browser automation
  aria-browser:
    image: browserless/chrome:latest
    container_name: aria-browser
    restart: unless-stopped
    environment:
      MAX_CONCURRENT_SESSIONS: 5
      CONNECTION_TIMEOUT: 60000
      TOKEN: ${BROWSERLESS_TOKEN:-}
    ports:
      - "3000:3000"
    networks:
      - aria-net

  # Clawdbot Gateway - AI Assistant Control UI
  # Uses LiteLLM as backend to route to local Ollama (qwen3-vl) or cloud models
  # Mounts aria_mind/ as workspace with aria_skills/, aria_agents/ for Python skill execution
  clawdbot:
    image: node:22-bookworm
    container_name: clawdbot
    restart: unless-stopped
    working_dir: /root
    environment:
      NODE_OPTIONS: "--max-old-space-size=1024"
      # Pin OpenClaw version - change here to upgrade, then: docker compose up -d --force-recreate clawdbot
      # Fork: https://github.com/Najia-afk/openclaw @ commit 9f703a4
      OPENCLAW_VERSION: "2026.2.6-3"
      OPENCLAW_CONFIG_PATH: "/root/.openclaw/openclaw.json"
      OPENCLAW_WORKSPACE: "/root/.openclaw/workspace"
      OPENCLAW_GATEWAY_PORT: "18789"
      OPENCLAW_GATEWAY_TOKEN: ${CLAWDBOT_TOKEN:-default-clawdbot-token}
      OPENCLAW_NO_ONBOARD: "1"
      OPENCLAW_NO_PROMPT: "1"
      # Custom system prompt for Aria (S-27)
      OPENCLAW_SYSTEM_PROMPT_FILE: "/root/.openclaw/system_prompt.txt"
      # Remote browser (aria-browser container via CDP)
      BROWSER_CDP_URL: http://aria-browser:3000
      # LiteLLM credentials for local model routing
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      # Cloud fallbacks
      MOONSHOT_KIMI_KEY: ${MOONSHOT_KIMI_KEY:-}
      # Database connection for Python skills
      DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      # Ollama for local LLM
      OLLAMA_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: hf.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF:Q3_K_S
      # Moltbook credentials
      MOLTBOOK_TOKEN: ${MOLTBOOK_TOKEN:-}
      MOLTBOOK_API_KEY: ${MOLTBOOK_TOKEN:-}
      MOLTBOOK_API_URL: ${MOLTBOOK_API_URL:-https://www.moltbook.com/api/v1}
      # Church of Molt (https://molt.church)
      MOLT_CHURCH_API_KEY: ${MOLT_CHURCH_API_KEY:-}
      MOLT_CHURCH_URL: ${MOLT_CHURCH_URL:-https://molt.church}
      MOLT_CHURCH_AGENT: ${MOLT_CHURCH_AGENT:-Aria}
      # Local aria-api for backup persistence
      ARIA_API_URL: http://aria-api:8000
      # Python path for Aria modules
      PYTHONPATH: /root/.openclaw/workspace:/root/.openclaw/workspace/skills:/root/repo
    volumes:
      - openclaw_data:/root/.openclaw
      # Mount FULL git repo (read-only — Aria reads, never writes directly)
      - ../../:/root/repo:ro
      # Mount aria_mind as the OpenClaw workspace (read-write — OpenClaw needs write access)
      - ../../aria_mind:/root/.openclaw/workspace
      # Mount aria_memories for file-based artifacts (read-write — Aria's writable space)
      - ../../aria_memories:/root/.openclaw/aria_memories
      # Mount aria_souvenirs (read-only — creative artifacts)
      - ../../aria_souvenirs:/root/.openclaw/aria_souvenirs:ro
      # Mount Python skill modules into workspace/skills/
      # NOTE: Each skill subdirectory now contains skill.json for OpenClaw
      - ../../aria_skills:/root/.openclaw/workspace/skills/aria_skills:ro
      - ../../aria_agents:/root/.openclaw/workspace/skills/aria_agents:ro
      - ../../aria_models:/root/.openclaw/workspace/aria_models:ro
      - ../../skills:/root/.openclaw/workspace/skills/legacy:ro
      # Mount patch artifacts
      - ../../patch:/root/.openclaw/patches:ro
      # Mount tests + config for pytest skill
      - ../../tests:/root/.openclaw/workspace/tests:ro
      - ../../pyproject.toml:/root/.openclaw/workspace/pyproject.toml:ro
      - ./openclaw-entrypoint.sh:/openclaw-entrypoint.sh:ro
      # Mount OpenClaw config template
      - ./openclaw-config.json:/root/.openclaw/openclaw-config-template.json:ro
      # Custom system prompt for Aria (S-27)
      - ../../prompts/system_prompt.txt:/root/.openclaw/system_prompt.txt:ro
    ports:
      - "18789:18789"
    depends_on:
      aria-db:
        condition: service_healthy
      litellm:
        condition: service_started
    command: ["bash", "/openclaw-entrypoint.sh"]
    networks:
      - aria-net
    mem_limit: ${CLAWDBOT_MEM_LIMIT:-1g}
    cpus: ${CLAWDBOT_CPU_LIMIT:-1.0}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Tor Proxy for privacy
  tor-proxy:
    image: dperson/torproxy:latest
    container_name: tor-proxy
    restart: unless-stopped
    ports:
      - "9050:9050"
      - "9051:9051"
    networks:
      - aria-net

  # Self-signed TLS cert generator (runs once if missing)
  certs-init:
    image: alpine:3.20
    container_name: aria-certs-init
    restart: "no"
    volumes:
      - ./certs:/certs
    command: >
      sh -c "apk add --no-cache openssl; if [ ! -f /certs/cert.pem ] || [ ! -f /certs/key.pem ]; then \
      openssl req -x509 -newkey rsa:4096 -nodes -keyout /certs/key.pem -out /certs/cert.pem -days 3650 \
      -subj \"/C=US/ST=Local/L=LAN/O=Aria/CN=aria.local\"; fi"
    networks:
      - aria-net

  # Traefik reverse proxy (HTTPS)
  # Token injection via envsubst at startup - NO HARDCODED SECRETS
  traefik:
    image: traefik:v3.1
    container_name: traefik
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/traefik-entrypoint.sh"]
    command:
      - "--api=true"
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--ping=true"
      - "--providers.file.filename=/etc/traefik/dynamic.yaml"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.web.transport.respondingTimeouts.readTimeout=120s"
      - "--entrypoints.web.transport.respondingTimeouts.writeTimeout=120s"
      - "--entrypoints.web.transport.respondingTimeouts.idleTimeout=300s"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.websecure.transport.respondingTimeouts.readTimeout=120s"
      - "--entrypoints.websecure.transport.respondingTimeouts.writeTimeout=120s"
      - "--entrypoints.websecure.transport.respondingTimeouts.idleTimeout=300s"
      - "--metrics.prometheus=true"
    environment:
      CLAWDBOT_TOKEN: ${CLAWDBOT_TOKEN:-default-clawdbot-token}
    ports:
      - "0.0.0.0:80:80"
      - "0.0.0.0:443:443"
      - "0.0.0.0:8081:8080"
    volumes:
      - ./traefik-entrypoint.sh:/traefik-entrypoint.sh:ro
      - ./traefik-dynamic.template.yaml:/etc/traefik/dynamic.template.yaml:ro
      - ./certs:/certs:ro
    depends_on:
      certs-init:
        condition: service_completed_successfully
      aria-web:
        condition: service_started
      aria-api:
        condition: service_started
      clawdbot:
        condition: service_started
      litellm:
        condition: service_started
    networks:
      - aria-net
    mem_limit: ${TRAEFIK_MEM_LIMIT:-512m}
    cpus: ${TRAEFIK_CPU_LIMIT:-0.5}

  # LiteLLM Router for model management
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      MOONSHOT_KIMI_KEY: ${MOONSHOT_KIMI_KEY:-}
      OPEN_ROUTER_KEY: ${OPEN_ROUTER_KEY:-}
      OPEN_ROUTER_KEY_DEEP: ${OPEN_ROUTER_KEY_DEEP:-}
      # Use separate database for LiteLLM to prevent schema conflicts with Aria tables
      LITELLM_DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/litellm
      STORE_MODEL_IN_DB: "False"
      OLLAMA_API_BASE: http://host.docker.internal:11434
    volumes:
      - ./litellm-config.yaml:/app/config.yaml:ro
    ports:
      - "18793:4000"
    command: ["--config", "/app/config.yaml", "--detailed_debug"]
    networks:
      - aria-net
    mem_limit: ${LITELLM_MEM_LIMIT:-1024m}
    cpus: ${LITELLM_CPU_LIMIT:-1.0}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # NOTE: Ollama runs NATIVELY on macOS for Metal GPU acceleration (~20 tok/s)
  # Start with: OLLAMA_HOST=0.0.0.0:11434 ollama serve
  # Docker containers access via host.docker.internal:11434

  # Prometheus for metrics (optional: docker compose --profile monitoring up -d)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    profiles: ["monitoring"]
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.external-url=/prometheus/'
      - '--web.route-prefix=/prometheus/'
    ports:
      - "9090:9090"
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 0.5

  # Grafana for dashboards (optional: docker compose --profile monitoring up -d)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    profiles: ["monitoring"]
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s/grafana/"
      GF_SERVER_SERVE_FROM_SUB_PATH: "true"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 0.5

  # Aria Brain - Main AI Agent
  aria-brain:
    build:
      context: ../..
      dockerfile: Dockerfile
    container_name: aria-brain
    restart: unless-stopped
    environment:
      # Database
      DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      # Local LLM (Ollama - native on host)
      OLLAMA_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: hf.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF:Q3_K_S
      # LLM APIs (fallback)
      MOONSHOT_API_KEY: ${MOONSHOT_KIMI_KEY:-}
      # Moltbook
      MOLTBOOK_TOKEN: ${MOLTBOOK_TOKEN:-}
      MOLTBOOK_API_URL: ${MOLTBOOK_API_URL:-https://www.moltbook.com/api/v1}
      # Church of Molt (https://molt.church)
      MOLT_CHURCH_API_KEY: ${MOLT_CHURCH_API_KEY:-}
      MOLT_CHURCH_URL: ${MOLT_CHURCH_URL:-https://molt.church}
      MOLT_CHURCH_AGENT: ${MOLT_CHURCH_AGENT:-Aria}
      # LiteLLM (internal)
      LITELLM_URL: http://litellm:4000
      # Aria Email
      ARIA_EMAIL: ${ARIA_EMAIL:-}
      ARIA_EMAIL_PASSWORD: ${ARIA_EMAIL_PASSWORD:-}
    volumes:
      - aria_data:/app/data
      - aria_logs:/app/logs
    depends_on:
      aria-db:
        condition: service_healthy
      aria-api:
        condition: service_healthy
      litellm:
        condition: service_started
    networks:
      - aria-net
    # Keep running for interactive mode
    tty: true
    stdin_open: true
    mem_limit: ${ARIA_BRAIN_MEM_LIMIT:-512m}
    cpus: ${ARIA_BRAIN_CPU_LIMIT:-1.0}

  # PgAdmin for database management (optional: docker compose --profile monitoring up -d)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: aria-pgadmin
    restart: unless-stopped
    profiles: ["monitoring"]
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@aria.dev}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      SCRIPT_NAME: /pgadmin
    ports:
      - "5050:80"
    depends_on:
      - aria-db
    networks:
      - aria-net
    mem_limit: 256m
    cpus: 0.3

  # Aria Web Portal - Flask Dashboard
  aria-web:
    build:
      context: ../../src/web
      dockerfile: Dockerfile
    container_name: aria-web
    restart: unless-stopped
    environment:
      SECRET_KEY: ${WEB_SECRET_KEY:-aria-dev-secret-key}
      SERVICE_HOST: ${SERVICE_HOST:-localhost}
      API_BASE_URL: ${API_BASE_URL:-/api}
      CLAWDBOT_PUBLIC_URL: ${CLAWDBOT_PUBLIC_URL:-https://localhost/clawdbot/}
      GRAFANA_URL: http://grafana:3000
      PROMETHEUS_URL: http://prometheus:9090
      OLLAMA_URL: http://host.docker.internal:11434
      LITELLM_URL: http://litellm:4000
      CLAWDBOT_URL: http://clawdbot:18789
      CLAWDBOT_TOKEN: ${CLAWDBOT_TOKEN:-default-clawdbot-token}
    volumes:
      # Mount templates for live reload during development
      - ../../src/web/templates:/app/templates:ro
      - ../../src/web/static:/app/static:ro
    ports:
      - "5000:5000"
    depends_on:
      aria-db:
        condition: service_healthy
    networks:
      - aria-net
    mem_limit: ${ARIA_WEB_MEM_LIMIT:-256m}
    cpus: ${ARIA_WEB_CPU_LIMIT:-0.5}

  # Aria API - FastAPI backend (data routes)
  aria-api:
    build:
      context: ../../src/api
      dockerfile: Dockerfile
    container_name: aria-api
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      GRAFANA_URL: http://grafana:3000
      PROMETHEUS_URL: http://prometheus:9090
      OLLAMA_URL: http://host.docker.internal:11434
      MLX_URL: http://host.docker.internal:8080
      LITELLM_URL: http://litellm:4000
      CLAWDBOT_URL: http://clawdbot:18789
      PGADMIN_URL: http://aria-pgadmin:80
      API_BASE_URL: ${API_BASE_URL:-/api}
      # API keys for provider balance checks
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      MOONSHOT_KIMI_KEY: ${MOONSHOT_KIMI_KEY:-}
      OPEN_ROUTER_KEY: ${OPEN_ROUTER_KEY:-}
      OPEN_ROUTER_KEY_DEEP: ${OPEN_ROUTER_KEY_DEEP:-}
      # Service control (admin)
      ARIA_SERVICE_CONTROL_ENABLED: ${ARIA_SERVICE_CONTROL_ENABLED:-false}
      ARIA_ADMIN_TOKEN: ${ARIA_ADMIN_TOKEN:-}
      ARIA_SERVICE_CMD_LITELLM_RESTART: ${ARIA_SERVICE_CMD_LITELLM_RESTART:-docker restart litellm}
      ARIA_SERVICE_CMD_LITELLM_STOP: ${ARIA_SERVICE_CMD_LITELLM_STOP:-docker stop litellm}
      ARIA_SERVICE_CMD_OLLAMA_RESTART: ${ARIA_SERVICE_CMD_OLLAMA_RESTART:-}
      ARIA_SERVICE_CMD_OLLAMA_STOP: ${ARIA_SERVICE_CMD_OLLAMA_STOP:-}
      ARIA_SERVICE_CMD_MLX_RESTART: ${ARIA_SERVICE_CMD_MLX_RESTART:-}
      ARIA_SERVICE_CMD_MLX_STOP: ${ARIA_SERVICE_CMD_MLX_STOP:-}
      ARIA_SERVICE_CMD_ARIA_API_RESTART: ${ARIA_SERVICE_CMD_ARIA_API_RESTART:-docker restart aria-api}
      ARIA_SERVICE_CMD_ARIA_API_STOP: ${ARIA_SERVICE_CMD_ARIA_API_STOP:-docker stop aria-api}
      ARIA_SERVICE_CMD_ARIA_WEB_RESTART: ${ARIA_SERVICE_CMD_ARIA_WEB_RESTART:-docker restart aria-web}
      ARIA_SERVICE_CMD_ARIA_WEB_STOP: ${ARIA_SERVICE_CMD_ARIA_WEB_STOP:-docker stop aria-web}
      ARIA_SERVICE_CMD_CLAWDBOT_RESTART: ${ARIA_SERVICE_CMD_CLAWDBOT_RESTART:-docker restart clawdbot}
      ARIA_SERVICE_CMD_CLAWDBOT_STOP: ${ARIA_SERVICE_CMD_CLAWDBOT_STOP:-docker stop clawdbot}
      ARIA_SERVICE_CMD_GRAFANA_RESTART: ${ARIA_SERVICE_CMD_GRAFANA_RESTART:-docker restart grafana}
      ARIA_SERVICE_CMD_GRAFANA_STOP: ${ARIA_SERVICE_CMD_GRAFANA_STOP:-docker stop grafana}
      ARIA_SERVICE_CMD_PROMETHEUS_RESTART: ${ARIA_SERVICE_CMD_PROMETHEUS_RESTART:-docker restart prometheus}
      ARIA_SERVICE_CMD_PROMETHEUS_STOP: ${ARIA_SERVICE_CMD_PROMETHEUS_STOP:-docker stop prometheus}
      # Path to OpenClaw cron jobs file (mounted volume)
      OPENCLAW_JOBS_PATH: /openclaw/cron/jobs.json
    volumes:
      # Mount API source for live reload during development
      - ../../src/api:/app:ro
      # Mount models catalog (single source of truth for all model pricing)
      - ../../aria_models/models.yaml:/models/models.yaml:ro
      # Mount OpenClaw data for reading cron jobs
      - openclaw_data:/openclaw:ro
      # Mount aria_mind for soul/identity file access (read-only)
      - ../../aria_mind:/aria_mind:ro
      # Mount aria_skills for knowledge graph sync (read-only)
      - ../../aria_skills:/aria_skills:ro
      # Mount aria_memories for live memory view (read-only)
      - ../../aria_memories:/aria_memories:ro
      # Docker socket for service control (admin actions)
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8000:8000"
    depends_on:
      aria-db:
        condition: service_healthy
    networks:
      - aria-net
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    mem_limit: ${ARIA_API_MEM_LIMIT:-256m}
    cpus: ${ARIA_API_CPU_LIMIT:-0.5}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Aria Sandbox — isolated code execution environment (S-29)
  # Used by sandbox skill (aria_skills/sandbox/__init__.py) via httpx on port 9999
  aria-sandbox:
    build:
      context: ../sandbox
      dockerfile: Dockerfile
    container_name: aria-sandbox
    restart: unless-stopped
    profiles: ["sandbox"]
    environment:
      SANDBOX_PORT: "9999"
      SANDBOX_TIMEOUT: "60"
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 1.0

volumes:
  aria_pg_data:
  prometheus_data:
  grafana_data:
  aria_data:
  aria_logs:
  openclaw_data:
  

networks:
  aria-net:
    driver: bridge
