services:
  # PostgreSQL Database (pgvector enabled for semantic memory)
  aria-db:
    image: pgvector/pgvector:pg16
    container_name: aria-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-admin}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-admin}
      POSTGRES_DB: ${DB_NAME:-aria_warehouse}
      # Create litellm database on init
      POSTGRES_MULTIPLE_DATABASES: litellm
    volumes:
      - aria_pg_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - aria-net
    mem_limit: ${POSTGRES_MEM_LIMIT:-512m}
    cpus: ${POSTGRES_CPU_LIMIT:-1.0}

  # Headless Chrome for browser automation
  aria-browser:
    image: browserless/chrome:latest
    container_name: aria-browser
    restart: unless-stopped
    environment:
      MAX_CONCURRENT_SESSIONS: 5
      CONNECTION_TIMEOUT: 60000
      TOKEN: ${BROWSERLESS_TOKEN:-}
    ports:
      - "3000:3000"
    networks:
      - aria-net

  # ── Aria Engine (v2.0) — Standalone Python runtime ──────────────────────────
  # Replaces the legacy Node.js gateway with native Python engine
  # Provides: LLM gateway, scheduler, agent pool, health endpoint
  aria-engine:
    build:
      context: ../../
      dockerfile: Dockerfile
    container_name: aria-engine
    restart: unless-stopped
    command: ["python", "-m", "aria_engine"]
    environment:
      DATABASE_URL: postgresql+asyncpg://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      LITELLM_BASE_URL: http://litellm:4000/v1
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      ENGINE_DEBUG: ${ENGINE_DEBUG:-false}
      PYTHONPATH: /app
    volumes:
      - ../../aria_memories:/app/aria_memories
      - ../../aria_mind/soul:/app/aria_mind/soul:ro
      - ../../aria_models:/app/aria_models:ro
      - ../../aria_engine:/app/aria_engine:ro
    depends_on:
      aria-db:
        condition: service_healthy
      litellm:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - aria-net
    labels:
      - "com.aria.service=engine"
    mem_limit: ${ENGINE_MEM_LIMIT:-512m}
    cpus: ${ENGINE_CPU_LIMIT:-1.0}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Tor Proxy for privacy
  tor-proxy:
    image: dperson/torproxy:latest
    container_name: tor-proxy
    restart: unless-stopped
    ports:
      - "9050:9050"
      - "9051:9051"
    networks:
      - aria-net

  # Self-signed TLS cert generator (runs once if missing)
  certs-init:
    image: alpine:3.20
    container_name: aria-certs-init
    restart: "no"
    environment:
      SERVICE_HOST: ${SERVICE_HOST:-aria.local}
      MAC_LAN_IP: ${MAC_LAN_IP:-}
      MAC_TAILSCALE_IP: ${MAC_TAILSCALE_IP:-}
    volumes:
      - ./certs:/certs
    command: >
      sh -c "apk add --no-cache openssl; \
      SAN=\"DNS:localhost,DNS:aria.local,DNS:${SERVICE_HOST},IP:127.0.0.1\"; \
      if [ -n \"${MAC_LAN_IP}\" ]; then SAN=\"$$SAN,IP:${MAC_LAN_IP}\"; fi; \
      if [ -n \"${MAC_TAILSCALE_IP}\" ]; then SAN=\"$$SAN,IP:${MAC_TAILSCALE_IP}\"; fi; \
      openssl req -x509 -newkey rsa:4096 -nodes -keyout /certs/key.pem -out /certs/cert.pem -days 3650 \
      -subj \"/C=US/ST=Local/L=LAN/O=Aria/CN=${SERVICE_HOST}\" \
      -addext \"subjectAltName=$$SAN\""
    networks:
      - aria-net

  # Traefik reverse proxy (HTTPS)
  # Token injection via envsubst at startup - NO HARDCODED SECRETS
  traefik:
    image: traefik:v3.1
    container_name: traefik
    restart: unless-stopped
    entrypoint: ["/bin/sh", "/traefik-entrypoint.sh"]
    command:
      - "--api=true"
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--ping=true"
      - "--providers.file.filename=/etc/traefik/dynamic.yaml"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.web.transport.respondingTimeouts.readTimeout=120s"
      - "--entrypoints.web.transport.respondingTimeouts.writeTimeout=120s"
      - "--entrypoints.web.transport.respondingTimeouts.idleTimeout=300s"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.websecure.transport.respondingTimeouts.readTimeout=120s"
      - "--entrypoints.websecure.transport.respondingTimeouts.writeTimeout=120s"
      - "--entrypoints.websecure.transport.respondingTimeouts.idleTimeout=300s"
      - "--metrics.prometheus=true"
    ports:
      - "${TRAEFIK_HTTP_PORT:-8080}:80"
      - "${TRAEFIK_HTTPS_PORT:-8443}:443"
      - "${TRAEFIK_DASH_PORT:-8081}:8080"
    volumes:
      - ./traefik-entrypoint.sh:/traefik-entrypoint.sh:ro
      - ./traefik-dynamic.template.yaml:/etc/traefik/dynamic.template.yaml:ro
      - ./certs:/certs:ro
    depends_on:
      certs-init:
        condition: service_completed_successfully
      aria-web:
        condition: service_started
      aria-api:
        condition: service_started
      litellm:
        condition: service_started
    networks:
      - aria-net
    mem_limit: ${TRAEFIK_MEM_LIMIT:-512m}
    cpus: ${TRAEFIK_CPU_LIMIT:-0.5}

  # LiteLLM Router for model management
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      MOONSHOT_KIMI_KEY: ${MOONSHOT_KIMI_KEY:-}
      OPEN_ROUTER_KEY: ${OPEN_ROUTER_KEY:-}
      OPEN_ROUTER_KEY_DEEP: ${OPEN_ROUTER_KEY_DEEP:-}
      STORE_MODEL_IN_DB: "False"
      OLLAMA_API_BASE: http://host.docker.internal:11434
    volumes:
      - ./litellm-config.yaml:/app/config.yaml:ro
    ports:
      - "18793:4000"
    command: ["--config", "/app/config.yaml"]
    networks:
      - aria-net
    mem_limit: ${LITELLM_MEM_LIMIT:-1024m}
    cpus: ${LITELLM_CPU_LIMIT:-1.0}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # NOTE: Ollama runs NATIVELY on macOS for Metal GPU acceleration (~20 tok/s)
  # Start with: OLLAMA_HOST=0.0.0.0:11434 ollama serve
  # Docker containers access via host.docker.internal:11434

  # Prometheus for metrics (optional: docker compose --profile monitoring up -d)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    profiles: ["monitoring"]
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.external-url=/prometheus/'
      - '--web.route-prefix=/prometheus/'
    ports:
      - "9090:9090"
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 0.5

  # Grafana for dashboards (optional: docker compose --profile monitoring up -d)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    profiles: ["monitoring"]
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s/grafana/"
      GF_SERVER_SERVE_FROM_SUB_PATH: "true"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 0.5

  # Aria Brain - Main AI Agent
  aria-brain:
    build:
      context: ../..
      dockerfile: Dockerfile
    container_name: aria-brain
    restart: unless-stopped
    environment:
      # Database
      DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      # Local LLM (Ollama - native on host)
      OLLAMA_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: hf.co/unsloth/GLM-4.7-Flash-REAP-23B-A3B-GGUF:Q3_K_S
      # LLM APIs (fallback)
      MOONSHOT_API_KEY: ${MOONSHOT_KIMI_KEY:-}
      # Moltbook
      MOLTBOOK_TOKEN: ${MOLTBOOK_TOKEN:-}
      MOLTBOOK_API_URL: ${MOLTBOOK_API_URL:-https://www.moltbook.com/api/v1}
      # Telegram (social live mode)
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN:-}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID:-}
      # X / Twitter (social live mode)
      X_API_KEY: ${X_API_KEY:-}
      X_API_SECRET: ${X_API_SECRET:-}
      X_ACCESS_TOKEN: ${X_ACCESS_TOKEN:-}
      X_ACCESS_SECRET: ${X_ACCESS_SECRET:-}
      # Church of Molt (https://molt.church)
      MOLT_CHURCH_API_KEY: ${MOLT_CHURCH_API_KEY:-}
      MOLT_CHURCH_URL: ${MOLT_CHURCH_URL:-https://molt.church}
      MOLT_CHURCH_AGENT: ${MOLT_CHURCH_AGENT:-Aria}
      # LiteLLM (internal)
      LITELLM_URL: http://litellm:4000
      # Aria Email
      ARIA_EMAIL: ${ARIA_EMAIL:-}
      ARIA_EMAIL_PASSWORD: ${ARIA_EMAIL_PASSWORD:-}
    volumes:
      - aria_data:/app/data
      - aria_logs:/app/logs
    depends_on:
      aria-db:
        condition: service_healthy
      aria-api:
        condition: service_healthy
      litellm:
        condition: service_started
    networks:
      - aria-net
    # Keep running for interactive mode
    tty: true
    stdin_open: true
    mem_limit: ${ARIA_BRAIN_MEM_LIMIT:-512m}
    cpus: ${ARIA_BRAIN_CPU_LIMIT:-1.0}

  # PgAdmin for database management (optional: docker compose --profile monitoring up -d)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: aria-pgadmin
    restart: unless-stopped
    profiles: ["monitoring"]
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@aria.dev}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      SCRIPT_NAME: /pgadmin
    ports:
      - "5050:80"
    depends_on:
      - aria-db
    networks:
      - aria-net
    mem_limit: 256m
    cpus: 0.3

  # Aria Web Portal - Flask Dashboard
  aria-web:
    build:
      context: ../../src/web
      dockerfile: Dockerfile
    container_name: aria-web
    restart: unless-stopped
    environment:
      SECRET_KEY: ${WEB_SECRET_KEY:-aria-dev-secret-key}
      SERVICE_HOST: ${SERVICE_HOST:-localhost}
      API_BASE_URL: ${API_BASE_URL:-/api}
      GRAFANA_URL: http://grafana:3000
      PROMETHEUS_URL: http://prometheus:9090
      OLLAMA_URL: http://host.docker.internal:11434
      LITELLM_URL: http://litellm:4000
    volumes:
      # Mount templates for live reload during development
      - ../../src/web/templates:/app/templates:ro
      - ../../src/web/static:/app/static:ro
      - ../../src/web/app.py:/app/app.py:ro
    ports:
      - "5000:5000"
    depends_on:
      aria-db:
        condition: service_healthy
    networks:
      - aria-net
    mem_limit: ${ARIA_WEB_MEM_LIMIT:-256m}
    cpus: ${ARIA_WEB_CPU_LIMIT:-0.5}

  # Aria API - FastAPI backend (data routes)
  aria-api:
    build:
      context: ../../src/api
      dockerfile: Dockerfile
    container_name: aria-api
    restart: unless-stopped
    environment:
      # /aria_skills is bind-mounted; PYTHONPATH=/ makes it importable
      PYTHONPATH: /
      DATABASE_URL: postgresql://${DB_USER:-admin}:${DB_PASSWORD:-admin}@aria-db:5432/${DB_NAME:-aria_warehouse}
      GRAFANA_URL: http://grafana:3000
      PROMETHEUS_URL: http://prometheus:9090
      OLLAMA_URL: http://host.docker.internal:11434
      MLX_URL: http://host.docker.internal:8080
      LITELLM_URL: http://litellm:4000
      PGADMIN_URL: http://aria-pgadmin:80
      API_BASE_URL: ${API_BASE_URL:-/api}
      # API keys for provider balance checks
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-change-me}
      MOONSHOT_KIMI_KEY: ${MOONSHOT_KIMI_KEY:-}
      OPEN_ROUTER_KEY: ${OPEN_ROUTER_KEY:-}
      OPEN_ROUTER_KEY_DEEP: ${OPEN_ROUTER_KEY_DEEP:-}
      # Telegram + X credentials (for future API-side social integrations)
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN:-}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID:-}
      X_API_KEY: ${X_API_KEY:-}
      X_API_SECRET: ${X_API_SECRET:-}
      X_ACCESS_TOKEN: ${X_ACCESS_TOKEN:-}
      X_ACCESS_SECRET: ${X_ACCESS_SECRET:-}
      # Service control (admin)
      ARIA_SERVICE_CONTROL_ENABLED: ${ARIA_SERVICE_CONTROL_ENABLED:-false}
      ARIA_ADMIN_TOKEN: ${ARIA_ADMIN_TOKEN:-}
      ARIA_SERVICE_CMD_LITELLM_RESTART: ${ARIA_SERVICE_CMD_LITELLM_RESTART:-docker restart litellm}
      ARIA_SERVICE_CMD_LITELLM_STOP: ${ARIA_SERVICE_CMD_LITELLM_STOP:-docker stop litellm}
      ARIA_SERVICE_CMD_OLLAMA_RESTART: ${ARIA_SERVICE_CMD_OLLAMA_RESTART:-}
      ARIA_SERVICE_CMD_OLLAMA_STOP: ${ARIA_SERVICE_CMD_OLLAMA_STOP:-}
      ARIA_SERVICE_CMD_MLX_RESTART: ${ARIA_SERVICE_CMD_MLX_RESTART:-}
      ARIA_SERVICE_CMD_MLX_STOP: ${ARIA_SERVICE_CMD_MLX_STOP:-}
      ARIA_SERVICE_CMD_ARIA_API_RESTART: ${ARIA_SERVICE_CMD_ARIA_API_RESTART:-docker restart aria-api}
      ARIA_SERVICE_CMD_ARIA_API_STOP: ${ARIA_SERVICE_CMD_ARIA_API_STOP:-docker stop aria-api}
      ARIA_SERVICE_CMD_ARIA_WEB_RESTART: ${ARIA_SERVICE_CMD_ARIA_WEB_RESTART:-docker restart aria-web}
      ARIA_SERVICE_CMD_ARIA_WEB_STOP: ${ARIA_SERVICE_CMD_ARIA_WEB_STOP:-docker stop aria-web}
      ARIA_SERVICE_CMD_GRAFANA_RESTART: ${ARIA_SERVICE_CMD_GRAFANA_RESTART:-docker restart grafana}
      ARIA_SERVICE_CMD_GRAFANA_STOP: ${ARIA_SERVICE_CMD_GRAFANA_STOP:-docker stop grafana}
      ARIA_SERVICE_CMD_PROMETHEUS_RESTART: ${ARIA_SERVICE_CMD_PROMETHEUS_RESTART:-docker restart prometheus}
      ARIA_SERVICE_CMD_PROMETHEUS_STOP: ${ARIA_SERVICE_CMD_PROMETHEUS_STOP:-docker stop prometheus}
      SKILL_BACKFILL_ON_STARTUP: ${SKILL_BACKFILL_ON_STARTUP:-true}
    volumes:
      # Mount API source for live reload during development
      - ../../src/api:/app:ro
      # Mount models catalog (single source of truth for all model pricing)
      - ../../aria_models/models.yaml:/models/models.yaml:ro
      # Mount aria_models as importable Python package
      - ../../aria_models:/aria_models:ro
      # Mount aria_mind for soul/identity file access (read-only)
      - ../../aria_mind:/aria_mind:ro
      # Mount aria_engine for engine imports (read-only)
      - ../../aria_engine:/aria_engine:ro
      # Mount aria_skills for knowledge graph sync (read-only)
      - ../../aria_skills:/aria_skills:ro
      # Mount aria_memories for live memory view (read-only)
      - ../../aria_memories:/aria_memories:ro
      # Mount aria_agents for soul file browser (read-only)
      - ../../aria_agents:/aria_agents:ro
      # Mount aria_souvenirs for soul file browser (read-only)
      - ../../aria_souvenirs:/aria_souvenirs:ro
      # Docker socket for service control (admin actions)
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8000:8000"
    depends_on:
      aria-db:
        condition: service_healthy
    networks:
      - aria-net
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    mem_limit: ${ARIA_API_MEM_LIMIT:-256m}
    cpus: ${ARIA_API_CPU_LIMIT:-0.5}
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Aria Sandbox — isolated code execution environment (S-29)
  # Used by sandbox skill (aria_skills/sandbox/__init__.py) via httpx on port 9999
  aria-sandbox:
    build:
      context: ../sandbox
      dockerfile: Dockerfile
    container_name: aria-sandbox
    restart: unless-stopped
    profiles: ["sandbox"]
    environment:
      SANDBOX_PORT: "9999"
      SANDBOX_TIMEOUT: "60"
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
    networks:
      - aria-net
    mem_limit: 512m
    cpus: 1.0

volumes:
  aria_pg_data:
  prometheus_data:
  grafana_data:
  aria_data:
  aria_logs:

networks:
  aria-net:
    driver: bridge
