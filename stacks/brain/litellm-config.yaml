model_list:
  # Local Ollama model (native Metal GPU on host)
  # Primary model - can be called as "local-default" or "gpt-4o" (for OpenClaw compatibility)
  - model_name: local-default
    litellm_params:
      model: ollama/qwen3-vl:8b
      api_base: http://host.docker.internal:11434
    model_info:
      max_tokens: 8192
      input_cost_per_token: 0
      output_cost_per_token: 0

  # Alias for OpenClaw - routes gpt-4o requests to local Ollama
  - model_name: gpt-4o
    litellm_params:
      model: ollama/qwen3-vl:8b
      api_base: http://host.docker.internal:11434
    model_info:
      max_tokens: 8192
      input_cost_per_token: 0
      output_cost_per_token: 0

  # Gemini 3 Flash
  - model_name: gemini-3-flash
    litellm_params:
      model: gemini/gemini-3-flash
      api_key: os.environ/GOOGLE_GEMINI_KEY
    model_info:
      max_tokens: 1000000

  # Gemini 3 Pro
  - model_name: gemini-3-pro
    litellm_params:
      model: gemini/gemini-3-pro
      api_key: os.environ/GOOGLE_GEMINI_KEY
    model_info:
      max_tokens: 1000000

  # Gemini 2.5 Flash
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GOOGLE_GEMINI_KEY
    model_info:
      max_tokens: 1000000

  # Gemini 2.0 Flash
  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GOOGLE_GEMINI_KEY
    model_info:
      max_tokens: 1000000

  # Gemini Banana (alias to 2.0 Flash)
  - model_name: gemini-banana
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GOOGLE_GEMINI_KEY
    model_info:
      max_tokens: 1000000

  # Moonshot / Kimi (256K context)
  - model_name: kimi-k2.5
    litellm_params:
      model: moonshot/kimi-k2.5
      api_key: os.environ/MOONSHOT_KIMI_KEY
      api_base: https://api.moonshot.ai/v1
    model_info:
      max_tokens: 256000

  - model_name: kimi-k2-0905-preview
    litellm_params:
      model: moonshot/kimi-k2-0905-preview
      api_key: os.environ/MOONSHOT_KIMI_KEY
      api_base: https://api.moonshot.ai/v1
    model_info:
      max_tokens: 256000

  - model_name: kimi-k2-turbo-preview
    litellm_params:
      model: moonshot/kimi-k2-turbo-preview
      api_key: os.environ/MOONSHOT_KIMI_KEY
      api_base: https://api.moonshot.ai/v1
    model_info:
      max_tokens: 256000

  - model_name: kimi-k2-thinking
    litellm_params:
      model: moonshot/kimi-k2-thinking
      api_key: os.environ/MOONSHOT_KIMI_KEY
      api_base: https://api.moonshot.ai/v1
    model_info:
      max_tokens: 256000

  - model_name: kimi-k2-thinking-turbo
    litellm_params:
      model: moonshot/kimi-k2-thinking-turbo
      api_key: os.environ/MOONSHOT_KIMI_KEY
      api_base: https://api.moonshot.ai/v1
    model_info:
      max_tokens: 256000

router_settings:
  routing_strategy: simple-shuffle
  num_retries: 3
  timeout: 120
  allowed_fails: 3
  cooldown_time: 60

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/LITELLM_DATABASE_URL
  
litellm_settings:
  drop_params: true
  set_verbose: false
