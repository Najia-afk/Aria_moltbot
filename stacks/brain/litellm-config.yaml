# Aria LiteLLM Config — trimmed to confirmed working models
# Original source: aria_models/models.yaml → scripts/generate_configs.py
model_list:
# ── Moonshot/Kimi (Paid — PRIMARY) ───────────────────────────
- model_name: trinity-free
  litellm_params:
    model: openrouter/arcee-ai/trinity-large-preview:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: solar-pro-3-free
  litellm_params:
    model: openrouter/upstage/solar-pro-3:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: lfm-25-thinking-free
  litellm_params:
    model: openrouter/liquid/lfm-2.5-1.2b-thinking:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: lfm-25-instruct-free
  litellm_params:
    model: openrouter/liquid/lfm-2.5-1.2b-instruct:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: chimera-free
  litellm_params:
    model: openrouter/tngtech/deepseek-r1t2-chimera:free
    api_key: os.environ/OPEN_ROUTER_KEY_DEEP
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: trinity-mini-free
  litellm_params:
    model: openrouter/arcee-ai/trinity-mini:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: tng-r1t-chimera-free
  litellm_params:
    model: openrouter/tngtech/tng-r1t-chimera:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: nemotron-nano-12b-v2-vl-free
  litellm_params:
    model: openrouter/nvidia/nemotron-nano-12b-v2-vl:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: qwen3-coder-free
  litellm_params:
    model: openrouter/qwen/qwen3-coder:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: qwen3-next-free
  litellm_params:
    model: openrouter/qwen/qwen3-next-80b-a3b-instruct:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: nemotron-nano-9b-v2-free
  litellm_params:
    model: openrouter/nvidia/nemotron-nano-9b-v2:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: glm-free
  litellm_params:
    model: openrouter/z-ai/glm-4.5-air:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: deepseek-free
  litellm_params:
    model: openrouter/deepseek/deepseek-r1-0528:free
    api_key: os.environ/OPEN_ROUTER_KEY_DEEP
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: nemotron-free
  litellm_params:
    model: openrouter/nvidia/nemotron-3-nano-30b-a3b:free
    api_key: os.environ/OPEN_ROUTER_KEY_DEEP
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: gpt-oss-free
  litellm_params:
    model: openrouter/openai/gpt-oss-120b:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: gpt-oss-small-free
  litellm_params:
    model: openrouter/openai/gpt-oss-20b:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: venice-dolphin-free
  litellm_params:
    model: openrouter/cognitivecomputations/dolphin-mistral-24b-venice-edition:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: gemma-3n-e2b-free
  litellm_params:
    model: openrouter/google/gemma-3n-e2b-it:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 4096
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: gemma-3n-e4b-free
  litellm_params:
    model: openrouter/google/gemma-3n-e4b-it:free
    api_key: os.environ/OPEN_ROUTER_KEY
  model_info:
    max_tokens: 4096
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: kimi
  litellm_params:
    model: moonshot/kimi-k2.5
    api_key: os.environ/MOONSHOT_KIMI_KEY
    api_base: https://api.moonshot.ai/v1
  model_info:
    max_tokens: 16384
- model_name: kimi-k2.5
  litellm_params:
    model: moonshot/kimi-k2.5
    api_key: os.environ/MOONSHOT_KIMI_KEY
    api_base: https://api.moonshot.ai/v1
  model_info:
    max_tokens: 16384
- model_name: kimi-local
  litellm_params:
    model: moonshot/kimi-k2.5
    api_key: os.environ/MOONSHOT_KIMI_KEY
    api_base: https://api.moonshot.ai/v1
  model_info:
    max_tokens: 16384
- model_name: kimi-k2-thinking
  litellm_params:
    model: moonshot/kimi-k2-thinking
    api_key: os.environ/MOONSHOT_KIMI_KEY
    api_base: https://api.moonshot.ai/v1
  model_info:
    max_tokens: 16384
- model_name: kimi-k2-thinking-turbo
  litellm_params:
    model: moonshot/kimi-k2-thinking
    api_key: os.environ/MOONSHOT_KIMI_KEY
    api_base: https://api.moonshot.ai/v1
  model_info:
    max_tokens: 16384
- model_name: qwen-cpu-fallback
  litellm_params:
    model: ollama/qwen2.5:3b
    api_base: http://host.docker.internal:11434
  model_info:
    max_tokens: 4096
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: phi4-mini-local
  litellm_params:
    model: ollama/phi4-mini:3.8b
    api_base: http://host.docker.internal:11434
  model_info:
    max_tokens: 4096
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: qwen3-local
  litellm_params:
    model: ollama/qwen3:8b
    api_base: http://host.docker.internal:11434
  model_info:
    max_tokens: 4096
    input_cost_per_token: 0
    output_cost_per_token: 0
- model_name: nomic-embed-text
  litellm_params:
    model: ollama/nomic-embed-text
    api_base: http://host.docker.internal:11434
  model_info:
    max_tokens: 8192
    input_cost_per_token: 0
    output_cost_per_token: 0
litellm_settings:
  drop_params: true
  disable_streaming: true
  set_verbose: false

general_settings:
  database_url: "os.environ/DATABASE_URL"
  master_key: "os.environ/LITELLM_MASTER_KEY"
