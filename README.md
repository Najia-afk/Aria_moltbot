# Aria Blue âš¡ï¸

<img src="aria_mind/aria-profile-v1.png" alt="Aria Blue" width="200" align="right" style="margin-left: 20px; border-radius: 10px;">

> An autonomous AI agent with sharp, efficient, and secure vibes.

Aria is an autonomous AI agent built on the [OpenClaw](https://openclaw.ai) gateway architecture. She runs **local-first** with Qwen3-VL on Apple Silicon (Metal GPU), with Kimi cloud fallback. She integrates with Moltbook social platform, manages her own memory, and operates with a layered skill system.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OpenClaw Gateway (clawdbot:18789)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  aria_mind/ (Workspace - mounted read-only)                    â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ SOUL.md        # Persona, boundaries, model preferences   â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ IDENTITY.md    # Name: Aria Blue âš¡ï¸                       â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ AGENTS.md      # Sub-agent definitions                    â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ TOOLS.md       # Available skills configuration           â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ HEARTBEAT.md   # Scheduled tasks checklist                â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ MEMORY.md      # Long-term curated knowledge              â”‚     â”‚
â”‚  â”‚  â””â”€â”€ USER.md        # User profile (Najia)                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â”‚                                     â”‚
â”‚                      Model: litellm/qwen3-local                         â”‚
â”‚                      Fallbacks: kimi-k2.5 (litellm/kimi-local)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LiteLLM Router (:18793)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  qwen3-local     â†’ ollama/qwen3-vl:8b (Metal GPU, ~20 tok/s)    â”‚    â”‚
â”‚  â”‚  gpt-4o          â†’ ollama/qwen3-vl:8b (alias)                   â”‚    â”‚
â”‚  â”‚  local-default   â†’ ollama/qwen3-vl:8b (alias)                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL 16 (aria-db:5432)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚    aria_warehouse       â”‚    â”‚       litellm           â”‚             â”‚
â”‚  â”‚  â”œâ”€â”€ activity_log       â”‚    â”‚  â”œâ”€â”€ LiteLLM_* tables   â”‚             â”‚
â”‚  â”‚  â”œâ”€â”€ memories           â”‚    â”‚  â””â”€â”€ (Prisma managed)   â”‚             â”‚
â”‚  â”‚  â”œâ”€â”€ thoughts           â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚  â”‚  â”œâ”€â”€ goals              â”‚                                            â”‚
â”‚  â”‚  â”œâ”€â”€ social_posts       â”‚    âš ï¸ SEPARATE databases prevent           â”‚
â”‚  â”‚  â””â”€â”€ heartbeat_log      â”‚       LiteLLM Prisma from dropping        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       Aria's tables!                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
Aria_moltbot/
â”œâ”€â”€ aria_mind/           # OpenClaw workspace (mounted to clawdbot)
â”‚   â”œâ”€â”€ SOUL.md          # Persona, boundaries, model preferences
â”‚   â”œâ”€â”€ IDENTITY.md      # Name: Aria Blue, emoji: âš¡ï¸
â”‚   â”œâ”€â”€ AGENTS.md        # Sub-agent definitions
â”‚   â”œâ”€â”€ TOOLS.md         # Available skills & execution guide
â”‚   â”œâ”€â”€ HEARTBEAT.md     # Scheduled tasks checklist
â”‚   â”œâ”€â”€ MEMORY.md        # Long-term curated knowledge
â”‚   â”œâ”€â”€ USER.md          # User profile (Najia)
â”‚   â”œâ”€â”€ soul/            # Python soul implementation
â”‚   â”‚   â”œâ”€â”€ identity.py
â”‚   â”‚   â”œâ”€â”€ values.py
â”‚   â”‚   â””â”€â”€ boundaries.py
â”‚   â””â”€â”€ skills/          # Python skill modules (mounted at runtime)
â”‚       â”œâ”€â”€ aria_skills/ # Core skill implementations
â”‚       â”œâ”€â”€ aria_agents/ # Multi-agent orchestration
â”‚       â””â”€â”€ legacy/      # Original skill implementations
â”‚
â”œâ”€â”€ aria_skills/         # Skill implementations (Python)
â”‚   â”œâ”€â”€ base.py          # BaseSkill, SkillConfig, SkillResult
â”‚   â”œâ”€â”€ registry.py      # SkillRegistry with TOOLS.md parser
â”‚   â”œâ”€â”€ moltbook.py      # Moltbook social platform integration
â”‚   â”œâ”€â”€ database.py      # PostgreSQL with asyncpg
â”‚   â”œâ”€â”€ llm.py           # LLM routing (local Ollama + cloud fallback)
â”‚   â”œâ”€â”€ health.py        # Health monitoring
â”‚   â”œâ”€â”€ knowledge_graph.py # Knowledge graph
â”‚   â”œâ”€â”€ goals.py         # Goal & task scheduling
â”‚   â””â”€â”€ pytest_runner.py # Pytest runner
â”‚
â”œâ”€â”€ aria_agents/         # Multi-agent orchestration
â”‚   â”œâ”€â”€ base.py          # BaseAgent, AgentConfig, AgentMessage
â”‚   â”œâ”€â”€ loader.py        # AGENTS.md parser
â”‚   â””â”€â”€ coordinator.py   # Agent lifecycle & routing
â”‚
â”œâ”€â”€ openclaw_skills/     # OpenClaw UI skills (SKILL.md format)
â”‚   â”œâ”€â”€ aria-database/   # ğŸ—„ï¸ Database queries
â”‚   â”œâ”€â”€ aria-moltbook/   # ğŸ¦ Moltbook social platform
â”‚   â”œâ”€â”€ aria-health/     # ğŸ’š Health monitoring
â”‚   â”œâ”€â”€ aria-goals/      # ğŸ¯ Goal tracking
â”‚   â”œâ”€â”€ aria-knowledge-graph/  # ğŸ•¸ï¸ Knowledge graph
â”‚   â”œâ”€â”€ aria-llm/        # ğŸ§  LLM routing
â”‚   â””â”€â”€ aria-pytest/     # ğŸ§ª Pytest runner
â”‚
â”œâ”€â”€ skills/              # Legacy skill implementations
â”‚   â”œâ”€â”€ moltbook_poster.py
â”‚   â”œâ”€â”€ goal_scheduler.py
â”‚   â”œâ”€â”€ health_monitor.py
â”‚   â””â”€â”€ knowledge_graph.py
â”‚
â”œâ”€â”€ stacks/brain/        # Docker deployment (PRIMARY)
â”‚   â”œâ”€â”€ docker-compose.yml        # Full stack orchestration
â”‚   â”œâ”€â”€ openclaw-entrypoint.sh    # OpenClaw startup with Python skills
â”‚   â”œâ”€â”€ openclaw-config.json      # OpenClaw provider template
â”‚   â”œâ”€â”€ litellm-config.yaml       # Model routing (qwen3 â†’ Ollama)
â”‚   â”œâ”€â”€ init-scripts/             # PostgreSQL initialization
â”‚   â”‚   â”œâ”€â”€ 00-create-litellm-db.sh  # Creates separate litellm database
â”‚   â”‚   â””â”€â”€ 01-schema.sql            # Aria's 8 core tables
â”‚   â”œâ”€â”€ prometheus.yml            # Prometheus scrape config
â”‚   â””â”€â”€ .env                      # Environment configuration
â”‚
â””â”€â”€ tests/               # pytest test suite
    â”œâ”€â”€ conftest.py      # Fixtures
    â”œâ”€â”€ test_skills.py   # Skill unit tests
    â””â”€â”€ test_agents.py   # Agent unit tests
```

## ğŸ§  Model Configuration

Aria uses **local-first** LLM routing through LiteLLM:

| Priority | Model Alias | Routes To | Provider |
|----------|-------------|-----------|----------|
| 1 (Primary) | `litellm/qwen3-mlx` | MLX Server (port 8080) | Local MLX (Metal GPU) |
| 2 (FREE) | `litellm/glm-free` | OpenRouter GLM 4.5 Air | OpenRouter FREE |
| 3 (FREE) | `litellm/deepseek-free` | OpenRouter DeepSeek R1 | OpenRouter FREE |
| 4 (FREE) | `litellm/nemotron-free` | OpenRouter Nemotron 30B | OpenRouter FREE |
| 5 (Paid) | `litellm/kimi` | Moonshot Kimi K2.5 | Moonshot Cloud |

OpenClaw configuration (generated by `openclaw-entrypoint.sh`):
```json
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "litellm/qwen3-local",
        "fallbacks": ["litellm/kimi-local"]
      }
    }
  },
  "models": {
    "providers": {
      "litellm": {
        "baseUrl": "http://litellm:4000/v1/",
        "apiKey": "${CLAWDBOT_TOKEN}"
      }
    }
  }
}
```

## ğŸ³ Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Stack (stacks/brain)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  traefik          â”‚ HTTPS reverse proxy (ports 80/443)          â”‚
â”‚  aria-db          â”‚ PostgreSQL 16 (aria_warehouse + litellm)    â”‚
â”‚  aria-api         â”‚ FastAPI data API (port 8000)                â”‚
â”‚  aria-web         â”‚ Flask UI portal (port 5000)                 â”‚
â”‚  aria-brain       â”‚ Python agent container                      â”‚
â”‚  litellm          â”‚ LLM router (port 18793 â†’ internal 4000)     â”‚
â”‚  clawdbot         â”‚ OpenClaw gateway (port 18789)               â”‚
â”‚  grafana          â”‚ Monitoring dashboards (port 3001)           â”‚
â”‚  prometheus       â”‚ Metrics collection (port 9090)              â”‚
â”‚  pgadmin          â”‚ Database admin UI (port 5050)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Native Service (macOS host @ 192.168.1.53):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLX Server       â”‚ Metal GPU acceleration (~25-35 tok/s)       â”‚
â”‚                   â”‚ Port 8080, launchd managed                  â”‚
â”‚                   â”‚ Model: Qwen3-VLTO-8B-Instruct-mlx           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3/M4) for Metal GPU acceleration
- Docker & Docker Compose
- Git

### One-Button Deploy

```bash
# 1. Clone the repository
git clone https://github.com/Najia-afk/Aria_moltbot.git
cd Aria_moltbot/stacks/brain

# 2. Configure environment
cp .env.example .env
nano .env  # Add your API keys

# 3. MLX Server should be running via launchd (auto-starts on boot)
# Verify: ssh your-mac "curl -s http://localhost:8080/v1/models"
# Manual start if needed: mlx_lm.server --model nightmedia/Qwen3-VLTO-8B-Instruct-qx86x-hi-mlx --host 0.0.0.0 --port 8080

# 4. Deploy everything
docker compose up -d

# 5. Verify
docker compose ps
curl http://localhost:18789/health
```

### Configuration (.env)

```env
# Database (creates TWO databases: aria_warehouse + litellm)
DB_USER=aria_admin
DB_PASSWORD=your_secure_password
DB_NAME=aria_warehouse

# LiteLLM (routes to local Ollama)
LITELLM_MASTER_KEY=sk-aria-local-key

# Cloud fallbacks (Kimi)
MOONSHOT_KIMI_KEY=your_kimi_key

# OpenClaw Gateway
CLAWDBOT_TOKEN=your_secure_gateway_token

# Host configuration
SERVICE_HOST=192.168.1.53
```

### Fresh Deploy (Nuke & Rebuild)

```bash
cd stacks/brain
docker compose down -v          # Remove containers AND volumes
docker compose up -d            # Rebuild from scratch
docker compose ps               # Verify all 12 services healthy
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=aria_skills --cov=aria_agents --cov-report=html

# Run specific test file
pytest tests/test_skills.py -v
```

## ğŸ³ Docker Services

| Service | Port | Description |
|---------|------|-------------|
| Traefik | 80/443 | HTTPS routing |
| API | 8000 | FastAPI backend |
| Web | 5000 | Flask UI |
| LiteLLM | 18793 | LLM router (â†’ Ollama) |
| Grafana | 3001 | Monitoring |
| PGAdmin | 5050 | DB admin |
| Clawdbot | 18789 | OpenClaw gateway |
| Prometheus | 9090 | Metrics |

## ğŸ¤– Agent System

Agents defined in `aria_mind/AGENTS.md`:

| Agent | Role | Capabilities |
|-------|------|--------------|
| `aria` | Coordinator | Orchestrate, delegate, synthesize |
| `researcher` | Researcher | Search, verify, summarize |
| `social` | Social | Post, engage, moderate |
| `coder` | Coder | Generate, review, explain |
| `memory` | Memory | Store, recall, organize |

## ğŸ“ Skills

Available skills in `aria_mind/TOOLS.md` (executed via Python):

| Skill | Description | Execution |
|-------|-------------|-----------|
| `moltbook` | Social platform | `python3 run_skill.py moltbook post_status '{...}'` |
| `database` | PostgreSQL queries | `python3 run_skill.py database query '{...}'` |
| `knowledge_graph` | Entity relationships | `python3 run_skill.py knowledge_graph add_entity '{...}'` |
| `health` | System monitoring | `python3 run_skill.py health check_health '{}'` |
| `goals` | Task scheduling | `python3 run_skill.py goals create_goal '{...}'` |
| `llm` | Local LLM calls | `python3 run_skill.py llm generate '{...}'` |

### Skill Architecture

```
OpenClaw exec tool
       â”‚
       â–¼
python3 run_skill.py <skill> <function> '<args_json>'
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /root/.openclaw/workspace/skills/               â”‚
â”‚  â”œâ”€â”€ aria_skills/     # Core Python skills       â”‚
â”‚  â”‚   â”œâ”€â”€ base.py      # BaseSkill class          â”‚
â”‚  â”‚   â”œâ”€â”€ database.py  # PostgreSQL operations    â”‚
â”‚  â”‚   â”œâ”€â”€ moltbook.py  # Social platform          â”‚
â”‚  â”‚   â”œâ”€â”€ llm.py       # LLM routing              â”‚
â”‚  â”‚   â”œâ”€â”€ health.py    # Health monitoring        â”‚
â”‚  â”‚   â”œâ”€â”€ goals.py     # Goal tracking            â”‚
â”‚  â”‚   â””â”€â”€ knowledge_graph.py                      â”‚
â”‚  â”œâ”€â”€ aria_agents/     # Agent orchestration      â”‚
â”‚  â”‚   â”œâ”€â”€ base.py      # BaseAgent class          â”‚
â”‚  â”‚   â”œâ”€â”€ loader.py    # AGENTS.md parser         â”‚
â”‚  â”‚   â””â”€â”€ coordinator.py                          â”‚
â”‚  â””â”€â”€ legacy/          # Original skills          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ OpenClaw Features

OpenClaw provides Aria with powerful capabilities:

- **Exec Tool**: Run shell commands with background process support
- **Process Tool**: Manage long-running sessions (poll, kill, clear)
- **Heartbeat**: Periodic agent turns every 30 minutes (configurable)
- **Memory Search**: Vector-based semantic search over MEMORY.md and memory/ files
- **Session Management**: Auto-compaction when context window fills up
- **Multi-Agent Routing**: Route different channels to different agents

See [OpenClaw documentation](https://openclaw.ai/docs) for full details.

## ğŸ“„ License

MIT License

---

*Aria Blue âš¡ï¸ - Sharp, Efficient, Secure*
