# Aria Blue âš¡ï¸

> An autonomous AI agent with sharp, efficient, and secure vibes.

Aria is an autonomous AI agent built on the [OpenClaw](https://github.com/openclaw/openclaw) architecture. She integrates with Moltbook social platform, manages her own memory, and operates with a layered skill system.

## ğŸ—ï¸ Architecture

```
aria_mind/           # Core identity & configuration (OpenClaw workspace)
â”œâ”€â”€ SOUL.md          # Persona, boundaries, guidelines
â”œâ”€â”€ IDENTITY.md      # Name, emoji, avatar, handles
â”œâ”€â”€ AGENTS.md        # Sub-agent definitions
â”œâ”€â”€ TOOLS.md         # Available skills configuration
â”œâ”€â”€ HEARTBEAT.md     # Scheduled tasks, health checks
â”œâ”€â”€ BOOTSTRAP.md     # Initialization sequence
â”œâ”€â”€ MEMORY.md        # Long-term knowledge
â””â”€â”€ USER.md          # User profile

aria_skills/         # API-safe skill interfaces
â”œâ”€â”€ base.py          # BaseSkill, SkillConfig, SkillResult
â”œâ”€â”€ registry.py      # SkillRegistry with TOOLS.md parser
â”œâ”€â”€ moltbook.py      # Moltbook social platform
â”œâ”€â”€ database.py      # PostgreSQL with asyncpg
â”œâ”€â”€ llm.py           # LLM skills (local + cloud)
â”œâ”€â”€ health.py        # Health monitoring
â””â”€â”€ goals.py         # Goal & task scheduling

aria_agents/         # Multi-agent orchestration
â”œâ”€â”€ base.py          # BaseAgent, AgentConfig, AgentMessage
â”œâ”€â”€ loader.py        # AGENTS.md parser
â””â”€â”€ coordinator.py   # Agent lifecycle & routing

tests/               # pytest test suite
â”œâ”€â”€ conftest.py      # Fixtures
â”œâ”€â”€ test_skills.py   # Skill unit tests
â”œâ”€â”€ test_agents.py   # Agent unit tests
â””â”€â”€ test_integration.py  # End-to-end tests
```

## Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Stack                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  traefik          â”‚ HTTPS reverse proxy                     â”‚
â”‚  aria-db          â”‚ PostgreSQL database                     â”‚
â”‚  aria-api         â”‚ FastAPI data API                        â”‚
â”‚  aria-web         â”‚ Flask UI portal                         â”‚
â”‚  aria-brain       â”‚ Main agent container                    â”‚
â”‚  litellm          â”‚ LLM router                              â”‚
â”‚  grafana          â”‚ Monitoring dashboards                   â”‚
â”‚  prometheus       â”‚ Metrics collection                      â”‚
â”‚  pgadmin          â”‚ Database admin UI                       â”‚
â”‚  clawdbot         â”‚ OpenClaw gateway                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Native Ollama (Metal GPU) runs alongside Docker for optimal performance.
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose
- macOS with Apple Silicon (for native Ollama with Metal GPU)

### Installation

```bash
# Clone the repository
git clone https://github.com/aria-blue/aria.git
cd aria

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -e ".[dev]"
```

### Configuration

Copy `stacks/brain/.env.example` to `stacks/brain/.env` and fill in your values:

```env
# Database
DB_USER=aria_admin
DB_PASSWORD=YOUR_PASSWORD
DB_NAME=aria_warehouse

# Native Ollama (Metal GPU - runs on host, not Docker)
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen3-vl:8b

# LLM APIs (fallback)
GOOGLE_GEMINI_KEY=your_gemini_key
MOONSHOT_KIMI_KEY=your_moonshot_key
```

### Running Native Ollama (Metal GPU)

On macOS with Apple Silicon, run Ollama natively for GPU acceleration:

```bash
# Start native Ollama (Metal GPU)
OLLAMA_HOST=0.0.0.0:11434 ollama serve

# In another terminal, pull the model
ollama pull qwen3-vl:8b
```

### Running Docker Stack

```bash
cd stacks/brain
docker compose up -d
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=aria_skills --cov=aria_agents --cov-report=html

# Run specific test file
pytest tests/test_skills.py -v
```

## ğŸ³ Docker Services

| Service | Port | Description |
|---------|------|-------------|
| Traefik | 80/443 | HTTPS routing |
| API | 8000 | FastAPI backend |
| Web | 5000 | Flask UI |
| LiteLLM | 18793 | LLM router |
| Grafana | 3001 | Monitoring |
| PGAdmin | 5050 | DB admin |
| Clawdbot | 18789 | OpenClaw gateway |
| Prometheus | 9090 | Metrics |

## ğŸ¤– Agent System

Agents defined in `aria_mind/AGENTS.md`:

| Agent | Role | Capabilities |
|-------|------|--------------|
| `aria` | Coordinator | Orchestrate, delegate, synthesize |
| `researcher` | Researcher | Search, verify, summarize |
| `social` | Social | Post, engage, moderate |
| `coder` | Coder | Generate, review, explain |
| `memory` | Memory | Store, recall, organize |

## ğŸ“ Skills

Available skills in `aria_mind/TOOLS.md`:

| Skill | Description | Rate Limit |
|-------|-------------|------------|
| `moltbook` | Social platform | 5/hr, 20/day |
| `database` | PostgreSQL | - |
| `gemini` | Google LLM | 60/min |
| `moonshot` | Moonshot LLM | 10/min |
| `health_monitor` | System health | - |
| `goal_scheduler` | Task scheduling | - |

## ğŸ“„ License

MIT License

---

*Aria Blue âš¡ï¸ - Sharp, Efficient, Secure*
