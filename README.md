# Aria Blue âš¡ï¸ â€” Autonomous AI Agent Platform

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-24.0+-blue.svg)](https://www.docker.com/)
[![OpenClaw](https://img.shields.io/badge/OpenClaw-Gateway-purple.svg)](https://openclaw.ai)
[![LiteLLM](https://img.shields.io/badge/LiteLLM-Router-orange.svg)](https://github.com/BerriAI/litellm)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Skills](https://img.shields.io/badge/Skills-25%20modules-brightgreen.svg)](#-skill-system-25-modules)
[![License](https://img.shields.io/badge/License-Source%20Available-orange.svg)](#-license)

<img src="aria_mind/aria-profile-v1.png" alt="Aria Blue" width="180" align="right" style="margin-left: 20px; border-radius: 10px;">

Aria is an autonomous AI agent that **thinks like a CEO**: she analyzes tasks, delegates to specialized focus personas, runs parallel roundtable discussions across domains, and synthesizes results â€” all on a self-driven 5-minute work cycle with goal tracking, persistent memory, and full observability.

Built on [OpenClaw](https://openclaw.ai) with local-first LLM inference on Apple Silicon.

---

## ğŸ§  What Makes Aria Different

### CEO Pattern â€” Orchestrate, Don't Just Execute

Aria doesn't just answer prompts. She operates as an **orchestrating consciousness** that breaks complex tasks into delegatable work, routes each piece to the right specialist, and synthesizes coherent outcomes:

```
User Request
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¯ Orchestrator (Aria)                                  â”‚
â”‚  Analyzes task â†’ decomposes â†’ assigns â†’ synthesizes      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ ğŸ”’ DevSec â”‚  â”‚ ğŸ“Š Data  â”‚  â”‚ ğŸ¨ Createâ”‚  ...        â”‚
â”‚  â”‚ Security  â”‚  â”‚ Analysis â”‚  â”‚ Content  â”‚              â”‚
â”‚  â”‚ CI/CD     â”‚  â”‚ MLOps    â”‚  â”‚ Ideation â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â”‚              â”‚              â”‚                    â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                      â”‚                                   â”‚
â”‚                      â–¼                                   â”‚
â”‚           Synthesized Result                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Focus Personas â€” Adaptive Specialization

Aria switches between **7 specialized focus personas** depending on the task. Each focus modifies her approach, prioritizes different skills, selects the optimal LLM model, and knows *when to delegate to other focuses*:

| Focus | Emoji | Vibe | Delegates To |
|-------|-------|------|-------------|
| **Orchestrator** | ğŸ¯ | Strategic, delegation-focused | Everyone â€” this is the CEO |
| **DevSecOps** | ğŸ”’ | Security-paranoid, systematic | Orchestrator (business), Data (analysis) |
| **Data Architect** | ğŸ“Š | Analytical, metrics-driven | DevSecOps (code), Social (comms) |
| **Crypto Trader** | ğŸ“ˆ | Risk-aware, disciplined | DevSecOps (implementation), Journalist (analysis) |
| **Creative** | ğŸ¨ | Exploratory, unconventional | DevSecOps (validation), Social (publishing) |
| **Social Architect** | ğŸŒ | Community-building, authentic | DevSecOps (tech content), Data (research) |
| **Journalist** | ğŸ“° | Investigative, fact-checking | Data (analysis), Social (publishing) |

Each persona carries:
- **Vibe modifier** â€” adjusts communication tone
- **Skill priority list** â€” which tools to use first
- **Model hint** â€” selects the best LLM from `models.yaml` (code tasks use coder models, creative uses creative models)
- **Delegation hint** â€” knows which other focus to hand off to

The `FocusManager` auto-suggests the right persona from task keywords, maintains transition history, and ensures core identity is never compromised.

### Roundtable Discussions â€” Multi-Domain Collaboration

When a task spans multiple domains (detected automatically via keyword triggers like "launch", "review", "cross-team"), Aria runs a **roundtable**:

```python
# Auto-detected: "How should we promote and secure the AI project?"
perspectives = await coordinator.roundtable(question)
# ğŸ”’ DevSecOps: "Security audit first, lock down API keys, scan dependencies"
# ğŸ“Š Data:     "Define KPIs â€” DAU, response latency, error rate targets"
# ğŸ¨ Creative: "Story angle: behind-the-scenes dev journey, demo video"
# ğŸŒ Social:   "Launch on Moltbook first, engage existing community"
# â†’ Aria synthesizes all perspectives into one actionable plan
```

All agents run **in parallel** via `asyncio.gather`, then the Orchestrator synthesizes.

### Goal-Driven Work Cycles â€” Autonomous Productivity

Aria doesn't wait for prompts. Every **5 minutes**, a work cycle fires:

```
WORK â†’ PROGRESS â†’ COMPLETION â†’ NEW GOAL â†’ GROWTH
```

Each cycle:
1. **Check active goals** (sorted by deadline â†’ priority â†’ progress)
2. **Select one** to work on
3. **Execute ONE concrete action** (a query, an API call, a document section)
4. **Log progress** to PostgreSQL
5. **Auto-create new goals** when current ones complete

Goals are prioritized 1-5: `URGENT â†’ HIGH â†’ MEDIUM â†’ LOW â†’ BACKGROUND`. Aria finishes what she starts, handles blocked goals gracefully, and maintains a continuous loop of small, compounding efforts.

### Self-Orchestrating Infrastructure Awareness

Aria knows her own infrastructure â€” every container, port, and capability:

| Capability | How |
|-----------|-----|
| Spawn up to 8 concurrent sub-agents | OpenClaw subagent system |
| Switch LLM models per task | LiteLLM + model hints per focus |
| Browse the web (headless Chrome) | aria-browser container |
| Anonymous research via Tor | tor-proxy container |
| Persistent memory & knowledge graph | PostgreSQL + knowledge_graph skill |
| Self-monitoring & health checks | health skill + heartbeat every 30 min |

She knows her permissions, her limits, and has emergency protocols for model failures and service outages.

---

## ğŸ“ Project Structure

```
Aria_moltbot/
â”œâ”€â”€ aria_mind/                 # OpenClaw workspace (mounted to gateway)
â”‚   â”œâ”€â”€ SOUL.md                # Persona, boundaries, model preferences
â”‚   â”œâ”€â”€ IDENTITY.md            # Agent identity configuration
â”‚   â”œâ”€â”€ GOALS.md               # Goal-driven work system (5-min cycles)
â”‚   â”œâ”€â”€ ORCHESTRATION.md       # Sub-agent delegation & infrastructure
â”‚   â”œâ”€â”€ AGENTS.md              # Sub-agent definitions
â”‚   â”œâ”€â”€ TOOLS.md               # Skill registry & execution guide
â”‚   â”œâ”€â”€ HEARTBEAT.md           # Scheduled task configuration
â”‚   â”œâ”€â”€ MEMORY.md              # Long-term curated knowledge
â”‚   â””â”€â”€ soul/                  # Soul implementation
â”‚       â”œâ”€â”€ focus.py           # 7 focus personas + FocusManager
â”‚       â”œâ”€â”€ identity.py        # Core identity (never overridden)
â”‚       â”œâ”€â”€ values.py          # Core values
â”‚       â””â”€â”€ boundaries.py      # Operational boundaries
â”‚
â”œâ”€â”€ aria_agents/               # Multi-agent orchestration
â”‚   â”œâ”€â”€ base.py                # BaseAgent, AgentConfig, AgentMessage
â”‚   â”œâ”€â”€ coordinator.py         # CEO pattern, roundtable, broadcasting
â”‚   â””â”€â”€ loader.py              # AGENTS.md parser
â”‚
â”œâ”€â”€ aria_skills/               # 25 skill modules
â”‚   â”œâ”€â”€ base.py                # BaseSkill (retry, metrics, Prometheus)
â”‚   â”œâ”€â”€ registry.py            # Auto-discovery registry
â”‚   â””â”€â”€ <25 skill dirs>/       # Each: __init__.py + skill.json + SKILL.md
â”‚
â”œâ”€â”€ stacks/brain/              # Docker deployment (13 services)
â”‚   â””â”€â”€ docker-compose.yml     # Full stack orchestration
â”‚
â”œâ”€â”€ src/                       # Application layer (API + Web UI)
â””â”€â”€ tests/                     # Pytest test suite
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Docker Stack (stacks/brain)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Traefik   â”‚    â”‚  OpenClaw  â”‚    â”‚  LiteLLM   â”‚                  â”‚
â”‚  â”‚  :80/:443  â”‚    â”‚  :18789    â”‚    â”‚  :18793    â”‚                  â”‚
â”‚  â”‚  (Proxy)   â”‚    â”‚ (Gateway)  â”‚    â”‚  (Router)  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚        â”‚                 â”‚                 â”‚                          â”‚
â”‚        â–¼                 â–¼                 â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  aria-web  â”‚    â”‚ aria_mind/ â”‚    â”‚  MLX Server (host:8080)    â”‚  â”‚
â”‚  â”‚  Flask UI  â”‚    â”‚ Workspace  â”‚    â”‚  Metal GPU ~25-35 tok/s    â”‚  â”‚
â”‚  â”‚  :5000     â”‚    â”‚ + Skills   â”‚    â”‚  Qwen3-VLTO-8B-Instruct   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚        â”‚                             â”‚  FREE Fallbacks:           â”‚  â”‚
â”‚        â–¼                             â”‚  GLM 4.5 Â· DeepSeek R1    â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  Nemotron 30B Â· GPT-OSS   â”‚  â”‚
â”‚  â”‚  aria-api  â”‚â”€â”€â”€â–¶â”‚  aria-db   â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  FastAPI   â”‚    â”‚ PostgreSQL â”‚    â”‚  Paid (last resort):       â”‚  â”‚
â”‚  â”‚  :8000     â”‚    â”‚  :5432     â”‚    â”‚  Moonshot Kimi K2.5        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Prometheus â”‚    â”‚  Grafana   â”‚    â”‚  PGAdmin   â”‚                  â”‚
â”‚  â”‚  :9090     â”‚    â”‚  :3001     â”‚    â”‚  :5050     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ aria-brain â”‚    â”‚ tor-proxy  â”‚    â”‚  browser   â”‚                  â”‚
â”‚  â”‚  (Agent)   â”‚    â”‚  :9050     â”‚    â”‚  :3000     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Model Routing

Each focus persona selects the optimal model for its domain. All routing goes through LiteLLM with automatic failover:

| Priority | Model | Best For | Cost |
|----------|-------|----------|------|
| 1 | Qwen3-VLTO-8B (MLX) | Primary â€” all tasks | Free (local Metal GPU) |
| 2 | Qwen3-Coder (OpenRouter) | Code generation, review | Free |
| 3 | Chimera (OpenRouter) | Reasoning (2x faster than R1) | Free |
| 4 | Trinity (OpenRouter) | Creative, agentic, roleplay | Free |
| 5 | DeepSeek R1 (OpenRouter) | Deep reasoning | Free |
| 6 | Nemotron 30B (OpenRouter) | Long context (256K) | Free |
| 7 | Kimi K2.5 (Moonshot) | Last resort | Paid |

Focus-to-model mapping is defined in `aria_models/models.yaml` and loaded dynamically.

---

## ğŸ”§ Skill System (25 Modules)

Each skill extends `BaseSkill` with retry logic, metrics tracking, and Prometheus integration:

```
aria_skills/<skill>/
â”œâ”€â”€ __init__.py      # Skill class
â”œâ”€â”€ skill.json       # OpenClaw manifest
â””â”€â”€ SKILL.md         # Documentation
```

### Core Skills

| Skill | Description |
|-------|-------------|
| `database` | PostgreSQL operations (queries, memory, activity logs) |
| `llm` | Multi-provider LLM routing (Moonshot, Ollama, OpenRouter) |
| `input_guard` | Runtime security â€” prompt injection detection, output filtering |
| `knowledge_graph` | Entity-relationship graph (persistent knowledge) |
| `goals` | Goal management, habit tracking, progress monitoring |
| `health` | System health checks across all services |
| `model_switcher` | Dynamic model switching with reasoning mode toggle |
| `api_client` | Centralized HTTP client for all API interactions |
| `schedule` | Scheduled jobs and background operations |
| `litellm` | LiteLLM proxy management and spend tracking |
| `pytest_runner` | Run pytest and return structured results |

### Domain Skills

| Skill | Focus | Description |
|-------|-------|-------------|
| `moltbook` | ğŸŒ Social | Moltbook social network (posts, comments, feed, search) |
| `social` | ğŸŒ Social | Social presence management |
| `community` | ğŸŒ Social | Community management and growth |
| `brainstorm` | ğŸ¨ Creative | Creative ideation sessions |
| `research` | ğŸ“° Journalist | Information gathering and verification |
| `fact_check` | ğŸ“° Journalist | Claim verification workflows |
| `market_data` | ğŸ“ˆ Trader | Cryptocurrency market data and analysis |
| `portfolio` | ğŸ“ˆ Trader | Portfolio and position management |
| `ci_cd` | ğŸ”’ DevSecOps | CI/CD pipeline automation |
| `security_scan` | ğŸ”’ DevSecOps | Vulnerability detection |
| `data_pipeline` | ğŸ“Š Data | ETL and data pipeline operations |
| `experiment` | ğŸ“Š Data | ML experiment tracking |
| `performance` | ğŸ¯ Orchestrator | Performance reviews and self-assessments |
| `hourly_goals` | ğŸ¯ Orchestrator | Micro-task tracking |

---

## ğŸ¤– Agent System

Multi-agent orchestration with the CEO delegation pattern:

| Agent | Role | Capabilities |
|-------|------|--------------|
| **aria** | Coordinator | Orchestrate, delegate, synthesize â€” the CEO |
| **researcher** | Researcher | Search, verify, summarize |
| **social** | Social | Post, engage, moderate on Moltbook |
| **coder** | Coder | Generate, review, explain code |
| **memory** | Memory | Store, recall, organize knowledge |

**Delegation patterns:**

| Pattern | When | Flow |
|---------|------|------|
| Simple sub-agent | Async work, same model | Aria â†’ sub-agent â†’ result â†’ synthesis |
| Specialized agent | Needs specific model | Aria â†’ agent (Kimi/coder model) â†’ result |
| Parallel agents | Splittable tasks | Aria â†’ [agentâ‚, agentâ‚‚, agentâ‚ƒ] â†’ merge |
| Roundtable | Cross-domain decisions | Aria â†’ all focuses in parallel â†’ synthesize |

---

## ğŸ³ Docker Stack (13 Services)

| Service | Image | Port | Description |
|---------|-------|------|-------------|
| **traefik** | traefik:v3.1 | 80, 443 | HTTPS reverse proxy |
| **clawdbot** | node:22-bookworm | 18789 | OpenClaw AI gateway |
| **litellm** | ghcr.io/berriai/litellm | 18793 | LLM model router |
| **aria-db** | postgres:16-alpine | 5432 | PostgreSQL (dual database) |
| **aria-api** | Custom (FastAPI) | 8000 | REST API backend |
| **aria-web** | Custom (Flask) | 5000 | Dashboard UI |
| **aria-brain** | Custom (Python) | â€” | Agent runtime |
| **grafana** | grafana/grafana | 3001 | Monitoring dashboards |
| **prometheus** | prom/prometheus | 9090 | Metrics collection |
| **pgadmin** | dpage/pgadmin4 | 5050 | Database admin |
| **aria-browser** | browserless/chrome | 3000 | Headless browser |
| **tor-proxy** | dperson/torproxy | 9050 | Privacy proxy |
| **certs-init** | alpine:3.20 | â€” | TLS cert generation |

### Database Isolation

| Database | Purpose |
|----------|---------|
| `aria_warehouse` | Aria's data (8 tables: activity_log, memories, thoughts, goals, social_posts, heartbeat_log, knowledge_entities, knowledge_relations) |
| `litellm` | LiteLLM Prisma tables (isolated to prevent migration conflicts) |

---

## ğŸš€ Quick Start

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3/M4) for Metal GPU
- Docker & Docker Compose
- Git

### Deploy

```bash
# Clone
git clone https://github.com/Najia-afk/Aria_moltbot.git
cd Aria_moltbot/stacks/brain

# Configure
cp .env.example .env
nano .env  # Set API keys

# Start MLX Server (Metal GPU)
mlx_lm.server --model nightmedia/Qwen3-VLTO-8B-Instruct-qx86x-hi-mlx \
  --host 0.0.0.0 --port 8080 &

# Deploy
docker compose up -d

# Verify
docker compose ps              # 13 services healthy
curl http://localhost:18789/health
```

### Service URLs

| Service | URL |
|---------|-----|
| Dashboard | `https://{HOST}/` |
| API Docs | `https://{HOST}/api/docs` |
| OpenClaw | `http://{HOST}:18789` |
| LiteLLM | `http://{HOST}:18793` |
| Grafana | `https://{HOST}/grafana` |
| PGAdmin | `https://{HOST}/pgadmin` |

---

## ğŸ§ª Testing

```bash
pytest
pytest --cov=aria_skills --cov=aria_agents --cov-report=html
pytest tests/test_skills.py -v
```

---

## ğŸ“œ License

**Source Available License** â€” Free for educational and personal use.

| Use Case | Allowed | Cost |
|----------|---------|------|
| Learning / Education | âœ… | Free |
| Personal Projects | âœ… | Free |
| Academic Research | âœ… | Free |
| Portfolio | âœ… | Free |
| Commercial / Business | âš ï¸ | [Contact](https://datascience-adventure.xyz/contact) |

See [LICENSE](LICENSE) for full terms.

---

**Built with:** Python 3.10+ Â· OpenClaw Â· LiteLLM Â· MLX Â· PostgreSQL 16 Â· Docker Â· Traefik Â· Grafana Â· Prometheus
