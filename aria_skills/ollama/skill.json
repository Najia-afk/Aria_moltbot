{
  "name": "aria-ollama",
  "version": "2.0.0",
  "description": "Ollama local LLM interface â€” generate text and chat via local Ollama server.",
  "author": "Aria Team",
  "layer": 2,
  "dependencies": ["api_client"],
  "focus_affinity": ["orchestrator"],
  "tools": [
    {
      "name": "generate",
      "description": "Generate text completion from a prompt using Ollama.",
      "input_schema": {
        "type": "object",
        "properties": {
          "prompt": { "type": "string", "description": "Input prompt" },
          "system": { "type": "string", "description": "Optional system prompt" },
          "temperature": { "type": "number", "description": "Sampling temperature (default: 0.7)" },
          "max_tokens": { "type": "integer", "description": "Maximum tokens (default: 2048)" }
        },
        "required": ["prompt"]
      }
    },
    {
      "name": "chat",
      "description": "Multi-turn chat completion via Ollama.",
      "input_schema": {
        "type": "object",
        "properties": {
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": { "type": "string" },
                "content": { "type": "string" }
              }
            },
            "description": "Chat messages with role and content"
          },
          "temperature": { "type": "number", "description": "Sampling temperature (default: 0.7)" },
          "max_tokens": { "type": "integer", "description": "Maximum tokens (default: 2048)" }
        },
        "required": ["messages"]
      }
    },
    {
      "name": "list_models",
      "description": "List available Ollama models.",
      "input_schema": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "set_model",
      "description": "Switch to a different Ollama model.",
      "input_schema": {
        "type": "object",
        "properties": {
          "model": { "type": "string", "description": "Model name to switch to" }
        },
        "required": ["model"]
      }
    }
  ]
}
