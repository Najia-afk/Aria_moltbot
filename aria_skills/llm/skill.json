{
  "name": "aria-llm",
  "version": "1.0.0",
  "description": "Access multiple LLM providers (Moonshot/Kimi, OpenRouter FREE, local MLX) for text generation and chat via LiteLLM routing.",
  "author": "Aria Team",
  "layer": 2,
  "dependencies": [
    "api_client"
  ],
  "focus_affinity": [
    "orchestrator"
  ],
  "tools": [
    {
      "name": "chat",
      "description": "Generate text or have a multi-turn conversation using specified model.",
      "parameters": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "The prompt to generate from"
          },
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string"
                },
                "content": {
                  "type": "string"
                }
              }
            },
            "description": "Array of chat messages with role and content"
          },
          "model": {
            "type": "string",
            "description": "Model to use (moonshot, ollama, openrouter)"
          },
          "system_prompt": {
            "type": "string",
            "description": "Optional system prompt"
          },
          "temperature": {
            "type": "number",
            "description": "Temperature for generation (0-1, default: 0.7)"
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum tokens to generate"
          }
        }
      }
    },
    {
      "name": "health_check",
      "description": "Check LLM provider health and availability.",
      "parameters": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "get_metrics",
      "description": "Get LLM usage metrics and statistics.",
      "parameters": {
        "type": "object",
        "properties": {}
      }
    }
  ],
  "run": "python3 /app/skills/run_skill.py llm {{tool}} '{{args_json}}'"
}
